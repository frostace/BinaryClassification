{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "import math\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize useful data\n",
    "with open('clinvar_conflicting_clean.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    temp_rows = list(reader)\n",
    "df = pd.read_csv('clinvar_conflicting_clean.csv', low_memory=False)\n",
    "columns_to_change = ['ORIGIN', 'EXON', 'INTRON', 'STRAND', 'LoFtool', 'CADD_PHRED', 'CADD_RAW', 'BLOSUM62']\n",
    "df[['CLNVI', 'MC', 'SYMBOL', 'Feature_type', 'Feature', 'BIOTYPE', \n",
    " 'cDNA_position', 'CDS_position', 'Protein_position', 'Amino_acids', 'Codons', \n",
    " 'BAM_EDIT', 'SIFT', 'PolyPhen']] = df[['CLNVI', 'MC', 'SYMBOL', 'Feature_type', 'Feature', 'BIOTYPE', \n",
    " 'cDNA_position', 'CDS_position', 'Protein_position', 'Amino_acids', 'Codons', \n",
    " 'BAM_EDIT', 'SIFT', 'PolyPhen']].fillna(value=\"null\")\n",
    "df = df.sample(n = df.shape[0])\n",
    "all_rows = df.values.tolist()\n",
    "row_num = len(all_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision stump part for Adaboost\n",
    "# ===========================================================\n",
    "def is_numeric(value):\n",
    "    return isinstance(value, int) or isinstance(value, float)\n",
    "\n",
    "# === LeafNode is the prediction result of this branch ===\n",
    "class LeafNode:\n",
    "    def __init__(self, rows, label = 1):\n",
    "        labels = []\n",
    "        self.true_idx = []\n",
    "        self.false_idx = []\n",
    "        for i in range(len(rows)):\n",
    "            row = rows[i]\n",
    "            labels.append(row[-1])\n",
    "            if row[-1] == label:\n",
    "                self.true_idx.append(i)\n",
    "            else:\n",
    "                self.false_idx.append(i)\n",
    "        self.prediction = collections.Counter(labels)\n",
    "        \n",
    "# === DecisionNode is an attribute / question used to partition the data ===\n",
    "class DecisionNode:\n",
    "    def __init__(self, question = None, left_branch = None, right_branch = None):\n",
    "        self.question = question\n",
    "        self.left_branch = left_branch\n",
    "        self.right_branch = right_branch\n",
    "    \n",
    "class DecisionStump:\n",
    "    def __init__(self, training_attribute, training_data, method = \"CART\"):\n",
    "        self.attribute = training_attribute     # takein attribute and data separately\n",
    "        self.train = training_data\n",
    "        self.row_num = len(self.train)\n",
    "        self.column_num = len(self.attribute)\n",
    "        self.method = method.upper()            # convert to upper case for general use\n",
    "        self.labels = self.uniq_val(-1)\n",
    "        self.significance = 0\n",
    "        if self.method not in [\"C4.5\", \"CART\", \"HYBRID\"]:\n",
    "            print(\"Error: Please choose a valid method! from: [C4.5, CART, HYBRID]\")\n",
    "            return None\n",
    "        self.root = self.build_stump(self.train)\n",
    "        self.accclassify_idx = self.root.left_branch.true_idx + self.root.right_branch.true_idx\n",
    "        self.misclassify_idx = self.root.left_branch.false_idx + self.root.right_branch.false_idx\n",
    "    \n",
    "    def uniq_val(self, column):\n",
    "        return set([self.train[i][column] for i in range(len(self.train))])\n",
    "    \n",
    "    # when raising a question.\n",
    "    # if it's a categorical attribute, we simply iterate all categories\n",
    "    # if it's a numeric attribute, we iterate the set of possible numeric values \n",
    "    class Question:\n",
    "        def __init__(self, column, ref_value, attribute):\n",
    "            self.column = column\n",
    "            self.ref_value = ref_value if ref_value else \"None\"\n",
    "            self.attri = attribute\n",
    "\n",
    "        def match(self, row):\n",
    "            if is_numeric(self.ref_value):\n",
    "                try:\n",
    "                    return row[self.column] >= self.ref_value\n",
    "                except:\n",
    "                    print(\"Error occured in \", row)\n",
    "                    return True\n",
    "            else:\n",
    "                return row[self.column] == self.ref_value\n",
    "\n",
    "        def __repr__(self):\n",
    "            operand = \">=\" if is_numeric(self.ref_value) else \"==\"\n",
    "            return \"Is %s %s %s?\" % (self.attri[self.column], operand, str(self.ref_value))\n",
    "    \n",
    "    # === Method 1 - C4.5 ===\n",
    "    def entropy(self, rows):\n",
    "        # === Bits used to store the information ===\n",
    "        labels = [row[-1] for row in rows]\n",
    "        frequency = collections.Counter(labels).values()\n",
    "        pop = sum(frequency)\n",
    "        H = 0\n",
    "        for f in frequency:\n",
    "            p = f / pop\n",
    "            H -= p * math.log(p, 2)\n",
    "        return H\n",
    "    \n",
    "    # === Method 2 - CART ===\n",
    "    def gini(self, rows):\n",
    "        # === Probability of misclassifying any of your label, which is impurity ===\n",
    "        labels = [row[-1] for row in rows]\n",
    "        frequency = collections.Counter(labels).values()\n",
    "        pop = sum(frequency)\n",
    "        gini = 1\n",
    "        for f in frequency:\n",
    "            p = f / pop\n",
    "            gini -= p ** 2\n",
    "        return gini\n",
    "    \n",
    "    # === Calculate Gain Info ===\n",
    "    def info(self, branches, root):\n",
    "        # === Objective: to find the best question which can maximize info ===\n",
    "        root_size = float(len(root))\n",
    "        if self.method == \"C4.5\":  # Here I pick the GainRatio Approach\n",
    "            root_uncertainty = self.entropy(root)\n",
    "            gain_info = root_uncertainty\n",
    "            split_info = 0\n",
    "            for branch in branches:\n",
    "                if not branch: continue\n",
    "                gain_info -= len(branch) / root_size * self.entropy(branch)\n",
    "                split_info -= float(len(branch)) / root_size * math.log(float(len(branch)) / root_size)\n",
    "#                 print(gain_info, split_info)\n",
    "            return gain_info / split_info\n",
    "        elif self.method == \"CART\":\n",
    "            root_uncertainty = self.gini(root)\n",
    "            gain_info = root_uncertainty\n",
    "            for branch in branches:\n",
    "                if not branch: continue\n",
    "                gain_info -= len(branch) / root_size * self.gini(branch)\n",
    "            return gain_info\n",
    "        elif self.method == \"HYBRID\":\n",
    "            pass\n",
    "        pass\n",
    "    \n",
    "    # === Here I only do Binary Partitions ===\n",
    "    def partition(self, rows, question):\n",
    "        true_rows = []\n",
    "        false_rows = []\n",
    "        for row in rows:\n",
    "            if question.match(row):\n",
    "                true_rows.append(row)\n",
    "            else:\n",
    "                false_rows.append(row)\n",
    "        return true_rows, false_rows\n",
    "    \n",
    "    # the question that achieves the max infomation attenuation is the best question\n",
    "    def find_best_question(self, rows):\n",
    "        max_info_attenuation = 0\n",
    "        # === Iterate through all question candidates ===\n",
    "        # === TODO: Maybe Iteration here can be optimized ===\n",
    "        for col in range(self.column_num - 1):\n",
    "            ref_candidates = self.uniq_val(col)\n",
    "            for ref_value in ref_candidates:\n",
    "                if ref_value == \"null\": continue # avoid using null values to generate questions\n",
    "                q = self.Question(col, ref_value, self.attribute)\n",
    "                temp_true_rows, temp_false_rows = self.partition(rows, q)\n",
    "                temp_info_attenuation = self.info([temp_true_rows, temp_false_rows], rows)\n",
    "                if temp_info_attenuation >= max_info_attenuation:\n",
    "                    max_info_attenuation = temp_info_attenuation\n",
    "                    best_question = q\n",
    "        return max_info_attenuation, best_question\n",
    "        \n",
    "    # === Input rows of data with attributes and labels ===\n",
    "    def build_stump(self, rows):\n",
    "        # === Assign all rows as root of the whole decision tree ===\n",
    "        # === We have met the leaf node if gini(rows) is 0 or no question candidates left ===\n",
    "        gain, q = self.find_best_question(rows)\n",
    "        true_rows, false_rows = self.partition(rows, q)\n",
    "        return DecisionNode(q, LeafNode(true_rows, 1), LeafNode(false_rows, 0))\n",
    "    \n",
    "    # === Input a row of data with attributes (and no label), predict its label with our decision tree ===\n",
    "    # === Actually it can contain a label, we just don't use it ===\n",
    "    # === walk down the decision tree until we reach the leaf node ===\n",
    "    def classify(self, row, node):\n",
    "        if isinstance(node, LeafNode):\n",
    "#             print(\"===\", node.prediction)\n",
    "            return node.prediction\n",
    "        \n",
    "        if node.question.match(row):\n",
    "#             print(node.question, True)\n",
    "            return self.classify(row, node.left_branch)\n",
    "        else:\n",
    "#             print(node.question, False)\n",
    "            return self.classify(row, node.right_branch)\n",
    "\n",
    "    # function to print the tree out\n",
    "    def print_tree(self, node, spacing=\"\"):\n",
    "        # Base case: we've reached a leaf\n",
    "        if isinstance(node, LeafNode):\n",
    "            print (spacing + \"Predict\", node.prediction)\n",
    "            return\n",
    "\n",
    "        # Print the question at this node\n",
    "        print (spacing + str(node.question))\n",
    "\n",
    "        # Call this function recursively on the true branch\n",
    "        print (spacing + '--> True:')\n",
    "        self.print_tree(node.left_branch, spacing + \"  \")\n",
    "\n",
    "        # Call this function recursively on the false branch\n",
    "        print (spacing + '--> False:')\n",
    "        self.print_tree(node.right_branch, spacing + \"  \")\n",
    "    \n",
    "    def test(self):\n",
    "        for i in range(self.column_num):\n",
    "            q = self.Question(i, self.train[1][i], self.attribute)\n",
    "            print(q)\n",
    "            print(q.match(1))\n",
    "            \n",
    "def normalized_weight(weight):\n",
    "    return np.divide(weight, sum(weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide whole dataset into training set and testing set\n",
    "# ===========================================================\n",
    "training_percentage = 0.001  # percent of partition of training dataset\n",
    "training_size = int(row_num * training_percentage)\n",
    "testing_size = row_num - training_size\n",
    "training_attribute = list(df.columns)\n",
    "training_data = all_rows[: training_size]  # training data should include header row\n",
    "testing_data = all_rows[training_size: ]   # testing data don't need to include header row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training stump 0\n",
      "stump 0 trained, alpha = 4.61\n",
      "training stump 1\n",
      "stump 1 trained, alpha = -2.08\n",
      "training stump 2\n",
      "stump 2 trained, alpha = -2.08\n",
      "training stump 3\n",
      "stump 3 trained, alpha = -2.08\n",
      "training stump 4\n",
      "stump 4 trained, alpha = -4.61\n",
      "training stump 5\n",
      "stump 5 trained, alpha = -4.61\n",
      "training stump 6\n",
      "stump 6 trained, alpha = -4.61\n",
      "training stump 7\n",
      "stump 7 trained, alpha = -4.61\n",
      "training stump 8\n",
      "stump 8 trained, alpha = -4.61\n",
      "training stump 9\n",
      "0.05620312690734863 seconds\n"
     ]
    }
   ],
   "source": [
    "# Recursively Training base learners\n",
    "# ===========================================================\n",
    "# let's train T = 10 base learners\n",
    "T = 10\n",
    "stump_forest = []\n",
    "weight = [1 / training_size for _ in range(training_size)]\n",
    "start = time.time()\n",
    "for i in range(T):\n",
    "    # train a decision stump\n",
    "    print(\"training stump %d\" % i)\n",
    "    stump = DecisionStump(training_attribute, training_data, \"CART\")\n",
    "    # calculate the total error of the stump\n",
    "    # TBD: maybe can be integrated into the training process\n",
    "    accuracy = len(stump.accclassify_idx) / training_size\n",
    "    \n",
    "    total_err_rate = 1 - accuracy\n",
    "    # update the significance level of this stump, remember not to divide by zero\n",
    "    stump.significance = 0.5 * math.log((1 - total_err_rate + 0.0001) / (total_err_rate + 0.0001))\n",
    "    # append stump into the forest\n",
    "    stump_forest.append(stump)\n",
    "    if len(stump_forest) == T: break  # early break\n",
    "    # update training_data weight, resample the training data with the updated weight distribution\n",
    "    true_scale = np.e ** stump.significance\n",
    "    for idx in stump.misclassify_idx:\n",
    "        weight[idx] = weight[idx] * true_scale\n",
    "    for idx in stump.accclassify_idx:\n",
    "        weight[idx] = weight[idx] * (1 / true_scale)\n",
    "    distrib = normalized_weight(weight)\n",
    "    print(\"stump %d trained, alpha = %.02f\" % (i, stump.significance))\n",
    "    resampled_idx = np.random.choice(training_size, training_size, p = distrib)\n",
    "    training_data = [training_data[idx] for idx in resampled_idx]\n",
    "#     print(training_data)\n",
    "#     stump.print_tree(stump.root)\n",
    "#     print(stump.misclassify_idx, stump.accclassify_idx)\n",
    "    weight = [1 / training_size for _ in range(training_size)]\n",
    "end = time.time()\n",
    "print(end - start, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "7.06307315826416\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "# ===========================================================\n",
    "accuracy = []\n",
    "for row in testing_data:\n",
    "    classification = stump.classify(row, stump.root)\n",
    "    if len(classification) == 1:\n",
    "        accuracy.append(int(classification.get(row[-1], 0) > 0))\n",
    "    else:\n",
    "        tot = sum(classification.values())\n",
    "        accuracy.append(classification.get(row[-1], 0) / tot)\n",
    "    \n",
    "print(sum(accuracy) / len(accuracy))\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.random.choice(a=[1,2,3,4,5], p=[0.2, 0.2, 0.2, 0.2, 0.2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
