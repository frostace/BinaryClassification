{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import lib\n",
    "# ===========================================================\n",
    "import csv\n",
    "import pandas as pd\n",
    "from datascience import *\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('fivethirtyeight')\n",
    "import collections\n",
    "import math\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CHROM</th>\n",
       "      <th>POS</th>\n",
       "      <th>REF</th>\n",
       "      <th>ALT</th>\n",
       "      <th>AF_ESP</th>\n",
       "      <th>AF_EXAC</th>\n",
       "      <th>AF_TGP</th>\n",
       "      <th>CLNDISDB</th>\n",
       "      <th>CLNDN</th>\n",
       "      <th>CLNHGVS</th>\n",
       "      <th>...</th>\n",
       "      <th>Codons</th>\n",
       "      <th>STRAND</th>\n",
       "      <th>BAM_EDIT</th>\n",
       "      <th>SIFT</th>\n",
       "      <th>PolyPhen</th>\n",
       "      <th>LoFtool</th>\n",
       "      <th>CADD_PHRED</th>\n",
       "      <th>CADD_RAW</th>\n",
       "      <th>BLOSUM62</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>955563</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>MedGen:C3808739,OMIM:615120|MedGen:CN169374</td>\n",
       "      <td>Myasthenic_syndrome,_congenital,_8|not_specified</td>\n",
       "      <td>NC_000001.10:g.955563G&gt;C</td>\n",
       "      <td>...</td>\n",
       "      <td>cGg/cCg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>0.421</td>\n",
       "      <td>11.390</td>\n",
       "      <td>1.133255</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>955597</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.42418</td>\n",
       "      <td>0.2826</td>\n",
       "      <td>MedGen:CN169374</td>\n",
       "      <td>not_specified</td>\n",
       "      <td>NC_000001.10:g.955597G&gt;T</td>\n",
       "      <td>...</td>\n",
       "      <td>ccG/ccT</td>\n",
       "      <td>1.0</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>0.421</td>\n",
       "      <td>8.150</td>\n",
       "      <td>0.599088</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>955619</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.03475</td>\n",
       "      <td>0.0088</td>\n",
       "      <td>MedGen:C3808739,OMIM:615120|MedGen:CN169374</td>\n",
       "      <td>Myasthenic_syndrome,_congenital,_8|not_specified</td>\n",
       "      <td>NC_000001.10:g.955619G&gt;C</td>\n",
       "      <td>...</td>\n",
       "      <td>Gtc/Ctc</td>\n",
       "      <td>1.0</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>0.421</td>\n",
       "      <td>3.288</td>\n",
       "      <td>0.069819</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>957640</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>0.0318</td>\n",
       "      <td>0.02016</td>\n",
       "      <td>0.0328</td>\n",
       "      <td>MedGen:C3808739,OMIM:615120|MedGen:CN169374</td>\n",
       "      <td>Myasthenic_syndrome,_congenital,_8|not_specified</td>\n",
       "      <td>NC_000001.10:g.957640C&gt;T</td>\n",
       "      <td>...</td>\n",
       "      <td>gaC/gaT</td>\n",
       "      <td>1.0</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>0.421</td>\n",
       "      <td>12.560</td>\n",
       "      <td>1.356499</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>976059</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00022</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>MedGen:CN169374</td>\n",
       "      <td>not_specified</td>\n",
       "      <td>NC_000001.10:g.976059C&gt;T</td>\n",
       "      <td>...</td>\n",
       "      <td>Ctg/Ttg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>0.421</td>\n",
       "      <td>17.740</td>\n",
       "      <td>2.234711</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  CHROM     POS REF ALT  AF_ESP  AF_EXAC  AF_TGP  \\\n",
       "0     1  955563   G   C  0.0000  0.00000  0.0000   \n",
       "1     1  955597   G   T  0.0000  0.42418  0.2826   \n",
       "2     1  955619   G   C  0.0000  0.03475  0.0088   \n",
       "3     1  957640   C   T  0.0318  0.02016  0.0328   \n",
       "4     1  976059   C   T  0.0000  0.00022  0.0010   \n",
       "\n",
       "                                      CLNDISDB  \\\n",
       "0  MedGen:C3808739,OMIM:615120|MedGen:CN169374   \n",
       "1                              MedGen:CN169374   \n",
       "2  MedGen:C3808739,OMIM:615120|MedGen:CN169374   \n",
       "3  MedGen:C3808739,OMIM:615120|MedGen:CN169374   \n",
       "4                              MedGen:CN169374   \n",
       "\n",
       "                                              CLNDN                   CLNHGVS  \\\n",
       "0  Myasthenic_syndrome,_congenital,_8|not_specified  NC_000001.10:g.955563G>C   \n",
       "1                                     not_specified  NC_000001.10:g.955597G>T   \n",
       "2  Myasthenic_syndrome,_congenital,_8|not_specified  NC_000001.10:g.955619G>C   \n",
       "3  Myasthenic_syndrome,_congenital,_8|not_specified  NC_000001.10:g.957640C>T   \n",
       "4                                     not_specified  NC_000001.10:g.976059C>T   \n",
       "\n",
       "   ...   Codons STRAND BAM_EDIT  SIFT PolyPhen LoFtool CADD_PHRED  CADD_RAW  \\\n",
       "0  ...  cGg/cCg    1.0     null  null     null   0.421     11.390  1.133255   \n",
       "1  ...  ccG/ccT    1.0     null  null     null   0.421      8.150  0.599088   \n",
       "2  ...  Gtc/Ctc    1.0     null  null     null   0.421      3.288  0.069819   \n",
       "3  ...  gaC/gaT    1.0     null  null     null   0.421     12.560  1.356499   \n",
       "4  ...  Ctg/Ttg    1.0     null  null     null   0.421     17.740  2.234711   \n",
       "\n",
       "  BLOSUM62 CLASS  \n",
       "0     -2.0     0  \n",
       "1      NaN     0  \n",
       "2      1.0     1  \n",
       "3      NaN     0  \n",
       "4      NaN     1  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize useful data\n",
    "# with open('clinvar_conflicting_clean.csv', 'r') as f:\n",
    "#     reader = csv.reader(f)\n",
    "#     temp_rows = list(reader)\n",
    "df = pd.read_csv('clinvar_conflicting_clean.csv', low_memory=False)\n",
    "columns_to_change = ['ORIGIN', 'EXON', 'INTRON', 'STRAND', 'LoFtool', 'CADD_PHRED', 'CADD_RAW', 'BLOSUM62']\n",
    "df[['CLNVI', 'MC', 'SYMBOL', 'Feature_type', 'Feature', 'BIOTYPE', \n",
    " 'cDNA_position', 'CDS_position', 'Protein_position', 'Amino_acids', 'Codons', \n",
    " 'BAM_EDIT', 'SIFT', 'PolyPhen']] = df[['CLNVI', 'MC', 'SYMBOL', 'Feature_type', 'Feature', 'BIOTYPE', \n",
    " 'cDNA_position', 'CDS_position', 'Protein_position', 'Amino_acids', 'Codons', \n",
    " 'BAM_EDIT', 'SIFT', 'PolyPhen']].fillna(value=\"null\")\n",
    "# df_zero = df.loc[df['CLASS'] == 0]\n",
    "# df_zero = df_zero.sample(n=10000)\n",
    "# df_one = df.loc[df['CLASS'] == 1]\n",
    "# df_one = df_one.sample(n=10000)\n",
    "\n",
    "# df = pd.concat([df_zero, df_one])\n",
    "# df = df.sample(n = df.shape[0])\n",
    "all_rows = df.values.tolist()\n",
    "row_num = len(all_rows)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision stump part for Adaboost\n",
    "# ===========================================================\n",
    "def is_numeric(value):\n",
    "    return isinstance(value, int) or isinstance(value, float)\n",
    "\n",
    "# === LeafNode is the prediction result of this branch ===\n",
    "class LeafNode:\n",
    "    def __init__(self, rows):\n",
    "#         labels = [row[-1] for row in rows]\n",
    "        labels = []\n",
    "        self.one_idx = []\n",
    "        self.zero_idx = []\n",
    "        for i in range(len(rows)):\n",
    "            row = rows[i]\n",
    "            labels.append(row[-1])\n",
    "            if row[-1] == 1:\n",
    "                self.one_idx.append(i)\n",
    "            else:\n",
    "                self.zero_idx.append(i)\n",
    "        self.prediction = collections.Counter(labels)\n",
    "        \n",
    "# === DecisionNode is an attribute / question used to partition the data ===\n",
    "class DecisionNode:\n",
    "    def __init__(self, question = None, left_branch = None, right_branch = None):\n",
    "        self.question = question\n",
    "        self.left_branch = left_branch\n",
    "        self.right_branch = right_branch\n",
    "    \n",
    "class DecisionStump:\n",
    "    def __init__(self, training_attribute, training_data, height, method = \"CART\"):\n",
    "        self.attribute = training_attribute     # takein attribute and data separately\n",
    "        self.train = training_data\n",
    "        self.height = height\n",
    "        self.row_num = len(self.train)\n",
    "        self.column_num = len(self.attribute)\n",
    "        self.method = method.upper()            # convert to upper case for general use\n",
    "        self.labels = self.uniq_val(-1)\n",
    "        self.significance = 0\n",
    "        if self.method not in [\"C4.5\", \"CART\", \"HYBRID\"]:\n",
    "            print(\"Error: Please choose a valid method! from: [C4.5, CART, HYBRID]\")\n",
    "            return None\n",
    "        \n",
    "        # train decision stump\n",
    "        self.root = self.build_stump(self.train, 1)\n",
    "        \n",
    "        # count ACC classifications and mis classifications to update weights\n",
    "        self.accclassify_idx = []\n",
    "        self.misclassify_idx = []\n",
    "        # walk down the decision stump to collect all misclassification indices\n",
    "        \n",
    "#         if self.root.left_branch.prediction.get(1, 0) > self.root.left_branch.prediction.get(0, 0):\n",
    "#             # then consider the prediction of this leaf node as 1: 1 -> correct, 0 -> misclassify\n",
    "#             self.accclassify_idx += self.root.left_branch.one_idx\n",
    "#             self.misclassify_idx += self.root.left_branch.zero_idx\n",
    "#         else:\n",
    "#             # then consider the prediction of this leaf node as 0: 0 -> correct, 1 -> misclassify\n",
    "#             self.accclassify_idx += self.root.left_branch.zero_idx\n",
    "#             self.misclassify_idx += self.root.left_branch.one_idx\n",
    "#         if self.root.right_branch.prediction.get(1, 0) > self.root.right_branch.prediction.get(0, 0):\n",
    "#             # then consider the prediction of this leaf node as 1: 1 -> correct, 0 -> misclassify\n",
    "#             self.accclassify_idx += self.root.right_branch.one_idx\n",
    "#             self.misclassify_idx += self.root.right_branch.zero_idx\n",
    "#         else:\n",
    "#             # then consider the prediction of this leaf node as 0: 0 -> correct, 1 -> misclassify\n",
    "#             self.accclassify_idx += self.root.right_branch.zero_idx\n",
    "#             self.misclassify_idx += self.root.right_branch.one_idx\n",
    "    \n",
    "    def uniq_val(self, column):\n",
    "        return set([self.train[i][column] for i in range(len(self.train))])\n",
    "    \n",
    "    # when raising a question.\n",
    "    # if it's a categorical attribute, we simply iterate all categories\n",
    "    # if it's a numeric attribute, we iterate the set of possible numeric values \n",
    "    class Question:\n",
    "        def __init__(self, column, ref_value, attribute):\n",
    "            self.column = column\n",
    "            self.ref_value = ref_value if ref_value else \"None\"\n",
    "            self.attri = attribute\n",
    "\n",
    "        def match(self, row):\n",
    "            if is_numeric(self.ref_value):\n",
    "                try:\n",
    "                    return row[self.column] >= self.ref_value\n",
    "                except:\n",
    "                    print(\"Error occured in \", row)\n",
    "                    return True\n",
    "            else:\n",
    "                return row[self.column] == self.ref_value\n",
    "\n",
    "        def __repr__(self):\n",
    "            operand = \">=\" if is_numeric(self.ref_value) else \"==\"\n",
    "            return \"Is %s %s %s?\" % (self.attri[self.column], operand, str(self.ref_value))\n",
    "    \n",
    "    # === Method 1 - C4.5 ===\n",
    "    def entropy(self, rows):\n",
    "        # === Bits used to store the information ===\n",
    "        labels = [row[-1] for row in rows]\n",
    "        frequency = collections.Counter(labels).values()\n",
    "        pop = sum(frequency)\n",
    "        H = 0\n",
    "        for f in frequency:\n",
    "            p = f / pop\n",
    "            H -= p * math.log(p, 2)\n",
    "        return H\n",
    "    \n",
    "    # === Method 2 - CART ===\n",
    "    def gini(self, rows):\n",
    "        # === Probability of misclassifying any of your label, which is impurity ===\n",
    "        labels = [row[-1] for row in rows]\n",
    "        frequency = collections.Counter(labels).values()\n",
    "        pop = sum(frequency)\n",
    "        gini = 1\n",
    "        for f in frequency:\n",
    "            p = f / pop\n",
    "            gini -= p ** 2\n",
    "        return gini\n",
    "    \n",
    "    # === Calculate Gain Info ===\n",
    "    def info(self, branches, root):\n",
    "        # === Objective: to find the best question which can maximize info ===\n",
    "        root_size = float(len(root))\n",
    "        if self.method == \"C4.5\":  # Here I pick the GainRatio Approach\n",
    "            root_uncertainty = self.entropy(root)\n",
    "            gain_info = root_uncertainty\n",
    "            split_info = 0\n",
    "            for branch in branches:\n",
    "                if not branch: continue\n",
    "                gain_info -= len(branch) / root_size * self.entropy(branch)\n",
    "                split_info -= float(len(branch)) / root_size * math.log(float(len(branch)) / root_size)\n",
    "#                 print(gain_info, split_info)\n",
    "            return gain_info / split_info\n",
    "        elif self.method == \"CART\":\n",
    "            root_uncertainty = self.gini(root)\n",
    "            gain_info = root_uncertainty\n",
    "            for branch in branches:\n",
    "                if not branch: continue\n",
    "                gain_info -= len(branch) / root_size * self.gini(branch)\n",
    "            return gain_info\n",
    "        elif self.method == \"HYBRID\":\n",
    "            pass\n",
    "        pass\n",
    "    \n",
    "    # === Here I only do Binary Partitions ===\n",
    "    def partition(self, rows, question):\n",
    "        true_rows = []\n",
    "        false_rows = []\n",
    "        for row in rows:\n",
    "            if question.match(row):\n",
    "                true_rows.append(row)\n",
    "            else:\n",
    "                false_rows.append(row)\n",
    "        return true_rows, false_rows\n",
    "    \n",
    "    # the question that achieves the max infomation attenuation is the best question\n",
    "    def find_best_question(self, rows):\n",
    "        max_info_attenuation = 0\n",
    "        best_question = self.Question(0, self.train[0][0], self.attribute)\n",
    "        # === Iterate through all question candidates ===\n",
    "        # === TODO: Maybe Iteration here can be optimized ===\n",
    "        for col in range(self.column_num - 1): # minus 1 to avoid using the label as attribute\n",
    "            ref_candidates = self.uniq_val(col)\n",
    "            for ref_value in ref_candidates:\n",
    "                if ref_value == \"null\": continue # avoid using null values to generate a question\n",
    "                q = self.Question(col, ref_value, self.attribute)\n",
    "                temp_true_rows, temp_false_rows = self.partition(rows, q)\n",
    "                temp_info_attenuation = self.info([temp_true_rows, temp_false_rows], rows)\n",
    "                if temp_info_attenuation >= max_info_attenuation:\n",
    "                    max_info_attenuation = temp_info_attenuation\n",
    "                    best_question = q\n",
    "        return max_info_attenuation, best_question\n",
    "        \n",
    "    # === Input rows of data with attributes and labels ===\n",
    "    def build_stump(self, rows, height):\n",
    "        # === Assign all rows as root of the whole decision tree ===\n",
    "        # === We have met the leaf node if gini(rows) is 0 or no question candidates left ===\n",
    "        gain_reduction, q = self.find_best_question(rows)\n",
    "        true_rows, false_rows = self.partition(rows, q)\n",
    "        if height == self.height:\n",
    "            return DecisionNode(q, LeafNode(true_rows), LeafNode(false_rows))\n",
    "        else:\n",
    "            return DecisionNode(q, self.build_tree(true_rows, height + 1), self.build_tree(false_rows, height + 1))\n",
    "    \n",
    "    # === Input a row of data with attributes (and no label), predict its label with our decision tree ===\n",
    "    # === Actually it can contain a label, we just don't use it ===\n",
    "    # === walk down the decision tree until we reach the leaf node ===\n",
    "    def classify(self, row, node):\n",
    "        if isinstance(node, LeafNode):\n",
    "            # do a mapping from label[1, 0] to label[1, -1]\n",
    "            return node.prediction\n",
    "#             return 1 if node.prediction.get(1, 0) / (node.prediction.get(1, 0) + node.prediction.get(0, 0)) > cutoff else -1\n",
    "        \n",
    "        if node.question.match(row):\n",
    "            return self.classify(row, node.left_branch)\n",
    "        else:\n",
    "            return self.classify(row, node.right_branch)\n",
    "\n",
    "    # function to print the tree out\n",
    "    def print_tree(self, node, spacing=\"\"):\n",
    "        # Base case: we've reached a leaf\n",
    "        if isinstance(node, LeafNode):\n",
    "            print (spacing + \"Predict\", node.prediction)\n",
    "            return\n",
    "\n",
    "        # Print the question at this node\n",
    "        print (spacing + str(node.question))\n",
    "\n",
    "        # Call this function recursively on the true branch\n",
    "        print (spacing + '--> True:')\n",
    "        self.print_tree(node.left_branch, spacing + \"  \")\n",
    "\n",
    "        # Call this function recursively on the false branch\n",
    "        print (spacing + '--> False:')\n",
    "        self.print_tree(node.right_branch, spacing + \"  \")\n",
    "    \n",
    "    def test(self):\n",
    "        for i in range(self.column_num):\n",
    "            q = self.Question(i, self.train[1][i], self.attribute)\n",
    "            print(q)\n",
    "            print(q.match(1))\n",
    "            \n",
    "def normalized_weight(weight):\n",
    "    return np.divide(weight, sum(weight))\n",
    "\n",
    "def rev_logit(val):\n",
    "    return 1 / (1 + np.exp(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide whole dataset into training set and testing set\n",
    "# ===========================================================\n",
    "training_percentage = 0.01  # percent of partition of training dataset\n",
    "training_size = int(row_num * training_percentage)\n",
    "testing_size = row_num - training_size\n",
    "training_attribute = list(df.columns)\n",
    "training_data = all_rows[: training_size]  # training data should include header row\n",
    "testing_data = all_rows[training_size: ]   # testing data don't need to include header row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training stump 0\n",
      "stump 0 trained, alpha = 0.62\n",
      "Is AF_TGP >= 0.0076?\n",
      "--> True:\n",
      "  Predict Counter({0: 156, 1: 7})\n",
      "--> False:\n",
      "  Predict Counter({0: 349, 1: 139})\n",
      "training stump 1\n",
      "stump 1 trained, alpha = 0.79\n",
      "Is CLNDN == Distal_spinal_muscular_atrophy|Distal_spinal_muscular_atrophy,_autosomal_recessive_4|Charcot-Marie-Tooth_disease,_recessive_intermediate_c?\n",
      "--> True:\n",
      "  Predict Counter({1: 18, 0: 1})\n",
      "--> False:\n",
      "  Predict Counter({0: 521, 1: 111})\n",
      "training stump 2\n",
      "stump 2 trained, alpha = 0.66\n",
      "Is AF_TGP >= 0.006999999999999999?\n",
      "--> True:\n",
      "  Predict Counter({0: 191, 1: 4})\n",
      "--> False:\n",
      "  Predict Counter({0: 323, 1: 133})\n",
      "training stump 3\n",
      "stump 3 trained, alpha = 0.68\n",
      "Is Consequence == inframe_insertion?\n",
      "--> True:\n",
      "  Predict Counter({1: 15})\n",
      "--> False:\n",
      "  Predict Counter({0: 504, 1: 132})\n",
      "training stump 4\n",
      "stump 4 trained, alpha = 0.68\n",
      "Is Codons == Cgg/Tgg?\n",
      "--> True:\n",
      "  Predict Counter({1: 27, 0: 4})\n",
      "--> False:\n",
      "  Predict Counter({0: 491, 1: 129})\n",
      "training stump 5\n",
      "stump 5 trained, alpha = 0.76\n",
      "Is LoFtool >= 0.8029999999999999?\n",
      "--> True:\n",
      "  Predict Counter({1: 52, 0: 23})\n",
      "--> False:\n",
      "  Predict Counter({0: 483, 1: 93})\n",
      "training stump 6\n",
      "stump 6 trained, alpha = 0.82\n",
      "Is CLNDN == Distal_spinal_muscular_atrophy|Distal_spinal_muscular_atrophy,_autosomal_recessive_4|Charcot-Marie-Tooth_disease,_recessive_intermediate_c|not_specified?\n",
      "--> True:\n",
      "  Predict Counter({1: 37})\n",
      "--> False:\n",
      "  Predict Counter({0: 508, 1: 106})\n",
      "training stump 7\n",
      "stump 7 trained, alpha = 0.67\n",
      "Is CLNDN == Distal_spinal_muscular_atrophy|Distal_spinal_muscular_atrophy,_autosomal_recessive_4|Charcot-Marie-Tooth_disease,_recessive_intermediate_c|not_specified?\n",
      "--> True:\n",
      "  Predict Counter({1: 25})\n",
      "--> False:\n",
      "  Predict Counter({0: 491, 1: 135})\n",
      "training stump 8\n",
      "stump 8 trained, alpha = 0.62\n",
      "Is CLNHGVS == NC_000001.10:g.2234410A>G?\n",
      "--> True:\n",
      "  Predict Counter({1: 30})\n",
      "--> False:\n",
      "  Predict Counter({0: 476, 1: 145})\n",
      "training stump 9\n",
      "11.304811954498291 seconds\n"
     ]
    }
   ],
   "source": [
    "# Recursively Training base learners\n",
    "# ===========================================================\n",
    "# let's train T = 10 base learners\n",
    "T = 10\n",
    "weakleaner_height = 3\n",
    "stump_forest = []\n",
    "weight = [1 / training_size for _ in range(training_size)]\n",
    "start = time.time()\n",
    "for i in range(T):\n",
    "    # train a decision stump\n",
    "    print(\"training stump %d\" % i)\n",
    "    stump = DecisionStump(training_attribute, training_data, height = weakleaner_height, \"CART\")\n",
    "    # calculate the total error of the stump\n",
    "    # TBD: maybe can be integrated into the training process\n",
    "    accuracy = len(stump.accclassify_idx) / training_size\n",
    "    \n",
    "    total_err_rate = 1 - accuracy\n",
    "    # update the significance level of this stump, remember not to divide by zero\n",
    "    stump.significance = 0.5 * math.log((1 - total_err_rate + 0.0001) / (total_err_rate + 0.0001))\n",
    "    # append stump into the forest\n",
    "    stump_forest.append(stump)\n",
    "    if len(stump_forest) == T: break  # early break\n",
    "    # update training_data weight, resample the training data with the updated weight distribution\n",
    "    true_scale = np.e ** stump.significance\n",
    "    for idx in stump.misclassify_idx:\n",
    "        weight[idx] = weight[idx] * true_scale\n",
    "    for idx in stump.accclassify_idx:\n",
    "        weight[idx] = weight[idx] * (1 / true_scale)\n",
    "    distrib = normalized_weight(weight)\n",
    "    print(\"stump %d trained, alpha = %.02f\" % (i, stump.significance))\n",
    "    resampled_idx = np.random.choice(training_size, training_size, p = distrib)\n",
    "    training_data = [training_data[idx] for idx in resampled_idx]\n",
    "    stump.print_tree(stump.root)\n",
    "    weight = [1 / training_size for _ in range(training_size)]\n",
    "end = time.time()\n",
    "print(end - start, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/frostace/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:31: RuntimeWarning: invalid value encountered in long_scalars\n"
     ]
    }
   ],
   "source": [
    "# New Testing Adaboost\n",
    "# TBD\n",
    "# ===========================================================\n",
    "# Compute TN, TP, FN, FP, etc. together with testing\n",
    "# ===========================================================\n",
    "ROC = Table(make_array('CUTOFF', 'TN', 'FN', 'FP', 'TP', 'ACC'))\n",
    "step_size = 0.05\n",
    "forest_size = len(stump_forest)\n",
    "CMap = {0: 'TN', 1: 'FN', 2: 'FP', 3: 'TP'}\n",
    "for cutoff in np.arange(0, 1 + step_size, step_size):\n",
    "    Confusion = {'TN': 0, 'FN': 0, 'FP': 0, 'TP': 0}\n",
    "    for row in testing_data:\n",
    "        true_rate_forest = 0\n",
    "        for tree_i in stump_forest:\n",
    "            # prediction is a counter of label 1 and 0\n",
    "            pred_counter = tree_i.classify(row, tree_i.root)\n",
    "            # do a mapping from label[1, 0] to label[1, -1]\n",
    "            true_rate_tree = 1 if pred_counter.get(1, 0) / (pred_counter.get(1, 0) + pred_counter.get(0, 0) + 0.00000001) > cutoff else -1\n",
    "            true_rate_forest += true_rate_tree * tree_i.significance\n",
    "#         true_rate_forest = rev_logit(true_rate_forest)\n",
    "#         true_pred = 1 if true_rate_forest >= cutoff else 0\n",
    "        true_pred = 0 if np.sign(true_rate_forest) <= 0 else 1\n",
    "        indicator = (true_pred << 1) + row[-1]\n",
    "        # accordingly update confusion matrix\n",
    "        Confusion[CMap[indicator]] += 1\n",
    "    # concatenate the confusion matrix values into the overall ROC Table\n",
    "    thisline = [cutoff] + list(Confusion.values()) + [(Confusion['TP'] + Confusion['TN']) / sum(Confusion.values())]\n",
    "    ROC = ROC.with_row(thisline)\n",
    "ROC = ROC.with_columns('SENSITIVITY', ROC.apply(lambda TP, FN: TP / (TP + FN + 0.00000001), 'TP', 'FN'))\n",
    "ROC = ROC.with_columns('FPR', ROC.apply(lambda TN, FP: FP / (TN + FP + 0.00000001), 'TN', 'FP'))\n",
    "ROC = ROC.with_column('FMEAS', ROC.apply(lambda TP, FP, FN: 2 * (TP / (TP + FN)) * (TP / (TP + FP)) / (TP / (TP + FN) + TP / (TP + FP)), 'TP', 'FP', 'FN'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>CUTOFF</th> <th>TN</th> <th>FN</th> <th>FP</th> <th>TP</th> <th>ACC</th> <th>SENSITIVITY</th> <th>FPR</th> <th>FMEAS</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>0     </td> <td>0    </td> <td>0    </td> <td>48249</td> <td>16288</td> <td>0.252382</td> <td>1          </td> <td>1       </td> <td>0.403044</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>0.05  </td> <td>0    </td> <td>0    </td> <td>48249</td> <td>16288</td> <td>0.252382</td> <td>1          </td> <td>1       </td> <td>0.403044</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>0.1   </td> <td>0    </td> <td>0    </td> <td>48249</td> <td>16288</td> <td>0.252382</td> <td>1          </td> <td>1       </td> <td>0.403044</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>0.15  </td> <td>0    </td> <td>0    </td> <td>48249</td> <td>16288</td> <td>0.252382</td> <td>1          </td> <td>1       </td> <td>0.403044</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>0.2   </td> <td>7099 </td> <td>497  </td> <td>41150</td> <td>15791</td> <td>0.35468 </td> <td>0.969487   </td> <td>0.852867</td> <td>0.431277</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>0.25  </td> <td>48249</td> <td>16288</td> <td>0    </td> <td>0    </td> <td>0.747618</td> <td>0          </td> <td>0       </td> <td>nan     </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>0.3   </td> <td>48249</td> <td>16288</td> <td>0    </td> <td>0    </td> <td>0.747618</td> <td>0          </td> <td>0       </td> <td>nan     </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>0.35  </td> <td>48249</td> <td>16288</td> <td>0    </td> <td>0    </td> <td>0.747618</td> <td>0          </td> <td>0       </td> <td>nan     </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>0.4   </td> <td>48249</td> <td>16288</td> <td>0    </td> <td>0    </td> <td>0.747618</td> <td>0          </td> <td>0       </td> <td>nan     </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>0.45  </td> <td>48249</td> <td>16288</td> <td>0    </td> <td>0    </td> <td>0.747618</td> <td>0          </td> <td>0       </td> <td>nan     </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>0.5   </td> <td>48249</td> <td>16288</td> <td>0    </td> <td>0    </td> <td>0.747618</td> <td>0          </td> <td>0       </td> <td>nan     </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>0.55  </td> <td>48249</td> <td>16288</td> <td>0    </td> <td>0    </td> <td>0.747618</td> <td>0          </td> <td>0       </td> <td>nan     </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>0.6   </td> <td>48249</td> <td>16288</td> <td>0    </td> <td>0    </td> <td>0.747618</td> <td>0          </td> <td>0       </td> <td>nan     </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>0.65  </td> <td>48249</td> <td>16288</td> <td>0    </td> <td>0    </td> <td>0.747618</td> <td>0          </td> <td>0       </td> <td>nan     </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>0.7   </td> <td>48249</td> <td>16288</td> <td>0    </td> <td>0    </td> <td>0.747618</td> <td>0          </td> <td>0       </td> <td>nan     </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>0.75  </td> <td>48249</td> <td>16288</td> <td>0    </td> <td>0    </td> <td>0.747618</td> <td>0          </td> <td>0       </td> <td>nan     </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>0.8   </td> <td>48249</td> <td>16288</td> <td>0    </td> <td>0    </td> <td>0.747618</td> <td>0          </td> <td>0       </td> <td>nan     </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>0.85  </td> <td>48249</td> <td>16288</td> <td>0    </td> <td>0    </td> <td>0.747618</td> <td>0          </td> <td>0       </td> <td>nan     </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>0.9   </td> <td>48249</td> <td>16288</td> <td>0    </td> <td>0    </td> <td>0.747618</td> <td>0          </td> <td>0       </td> <td>nan     </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>0.95  </td> <td>48249</td> <td>16288</td> <td>0    </td> <td>0    </td> <td>0.747618</td> <td>0          </td> <td>0       </td> <td>nan     </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>1     </td> <td>48249</td> <td>16288</td> <td>0    </td> <td>0    </td> <td>0.747618</td> <td>0          </td> <td>0       </td> <td>nan     </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ROC.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original Testing\n",
    "# ===========================================================\n",
    "accuracy = 0\n",
    "for row in testing_data:\n",
    "    overall_classification = 0\n",
    "    for stump in stump_forest:\n",
    "        classification = stump.classify(row, stump.root)\n",
    "        vote = stump.significance\n",
    "        overall_classification += classification * vote\n",
    "    # reverse mapping from label[1, -1] to label[1, 0]\n",
    "    predicted_label = 0 if np.sign(overall_classification) <= 0 else 1\n",
    "    if predicted_label == row[-1]: accuracy += 1\n",
    "#     print(classification, predicted_label, row[-1])\n",
    "accuracy = accuracy / testing_size\n",
    "print(\"%.03f%%\" % (accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing with a toy dataset\n",
    "# ===========================================================\n",
    "training_data = [\n",
    "    ['Green', 3, 1],\n",
    "    ['Yellow', 3, 1],\n",
    "    ['Red', 1, 0],\n",
    "    ['Red', 1, 0],\n",
    "    ['Yellow', 3, 1],\n",
    "    ['Red', 3, 1]\n",
    "]\n",
    "testing_data = [\n",
    "    ['Red', 2, 0],\n",
    "    ['Yellow', 3.5, 1],\n",
    "    ['Green', 3, 1]\n",
    "]\n",
    "training_attribute = ['Color', 'Diameter', 'Label']\n",
    "training_size = len(training_data)\n",
    "testing_size = len(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pf = df[]\n",
    "len(set(pd.Index(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10000, 10000])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount([row[-1] for row in all_rows])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
