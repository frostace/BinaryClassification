{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Function\n",
    "    * Raise_Question\n",
    "    * Find_best_question\n",
    "    * Partition\n",
    "    * Build_tree\n",
    "    * Predict\n",
    "* Class\n",
    "    * Attribute Node\n",
    "    * Leaf Node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation - reorganize the data\n",
    "1. label should be the last column\n",
    "2. make sure that catagorical data are in string format, numerical data are in int or float format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import lib\n",
    "# ===========================================================\n",
    "import csv\n",
    "from datascience import *\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('fivethirtyeight')\n",
    "import collections\n",
    "import math\n",
    "import sys\n",
    "# from tqdm import tqdm\n",
    "from time import sleep\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize useful data\n",
    "# ===========================================================\n",
    "# with open('clinvar_conflicting_clean.csv', 'r') as f:\n",
    "#     reader = csv.reader(f)\n",
    "#     temp_rows = list(reader)\n",
    "df = pd.read_csv('clinvar_conflicting_clean.csv', low_memory=False)\n",
    "columns_to_change = ['ORIGIN', 'EXON', 'INTRON', 'STRAND', 'LoFtool', 'CADD_PHRED', 'CADD_RAW', 'BLOSUM62']\n",
    "df[['CLNVI', 'MC', 'SYMBOL', 'Feature_type', 'Feature', 'BIOTYPE', \n",
    " 'cDNA_position', 'CDS_position', 'Protein_position', 'Amino_acids', 'Codons', \n",
    " 'BAM_EDIT', 'SIFT', 'PolyPhen']] = df[['CLNVI', 'MC', 'SYMBOL', 'Feature_type', 'Feature', 'BIOTYPE', \n",
    " 'cDNA_position', 'CDS_position', 'Protein_position', 'Amino_acids', 'Codons', \n",
    " 'BAM_EDIT', 'SIFT', 'PolyPhen']].fillna(value=0)\n",
    "df = df.sample(n = df.shape[0])\n",
    "columns_backup = df.columns\n",
    "all_rows = df.values.tolist()\n",
    "row_num = len(all_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CHROM</th>\n",
       "      <th>POS</th>\n",
       "      <th>REF</th>\n",
       "      <th>ALT</th>\n",
       "      <th>AF_ESP</th>\n",
       "      <th>AF_EXAC</th>\n",
       "      <th>AF_TGP</th>\n",
       "      <th>CLNDISDB</th>\n",
       "      <th>CLNDN</th>\n",
       "      <th>CLNHGVS</th>\n",
       "      <th>...</th>\n",
       "      <th>Codons</th>\n",
       "      <th>STRAND</th>\n",
       "      <th>BAM_EDIT</th>\n",
       "      <th>SIFT</th>\n",
       "      <th>PolyPhen</th>\n",
       "      <th>LoFtool</th>\n",
       "      <th>CADD_PHRED</th>\n",
       "      <th>CADD_RAW</th>\n",
       "      <th>BLOSUM62</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42457</th>\n",
       "      <td>13</td>\n",
       "      <td>52520508</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.00126</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>MedGen:C0019202,OMIM:277900,Orphanet:ORPHA905,...</td>\n",
       "      <td>Wilson_disease|not_specified|not_provided</td>\n",
       "      <td>NC_000013.10:g.52520508G&gt;A</td>\n",
       "      <td>...</td>\n",
       "      <td>aCg/aTg</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>deleterious</td>\n",
       "      <td>probably_damaging</td>\n",
       "      <td>0.0340</td>\n",
       "      <td>33.000</td>\n",
       "      <td>6.889543</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56604</th>\n",
       "      <td>19</td>\n",
       "      <td>855799</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>MedGen:C0221023,OMIM:162800,Orphanet:ORPHA2686...</td>\n",
       "      <td>Cyclical_neutropenia|Severe_congenital_neutrop...</td>\n",
       "      <td>NC_000019.9:g.855799G&gt;A</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>OK</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0124</td>\n",
       "      <td>7.931</td>\n",
       "      <td>0.567842</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34786</th>\n",
       "      <td>11</td>\n",
       "      <td>94194169</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>MedGen:C0027672,SNOMED_CT:699346009</td>\n",
       "      <td>Hereditary_cancer-predisposing_syndrome</td>\n",
       "      <td>NC_000011.9:g.94194169T&gt;G</td>\n",
       "      <td>...</td>\n",
       "      <td>aAg/aCg</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>tolerated</td>\n",
       "      <td>benign</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>18.050</td>\n",
       "      <td>2.282571</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27583</th>\n",
       "      <td>9</td>\n",
       "      <td>21971057</td>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>MedGen:C0027672,SNOMED_CT:699346009|MedGen:C15...</td>\n",
       "      <td>Hereditary_cancer-predisposing_syndrome|Heredi...</td>\n",
       "      <td>NC_000009.11:g.21971057C&gt;G</td>\n",
       "      <td>...</td>\n",
       "      <td>Ggg/Cgg</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>OK</td>\n",
       "      <td>deleterious</td>\n",
       "      <td>probably_damaging</td>\n",
       "      <td>0.1440</td>\n",
       "      <td>25.900</td>\n",
       "      <td>5.364526</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16982</th>\n",
       "      <td>5</td>\n",
       "      <td>256472</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>0.2783</td>\n",
       "      <td>0.17160</td>\n",
       "      <td>0.3353</td>\n",
       "      <td>Human_Phenotype_Ontology:HP:0002666,MedGen:C00...</td>\n",
       "      <td>Pheochromocytoma|Leigh_syndrome|Hereditary_can...</td>\n",
       "      <td>NC_000005.9:g.256472G&gt;A</td>\n",
       "      <td>...</td>\n",
       "      <td>gtG/gtA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>OK</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4320</td>\n",
       "      <td>8.009</td>\n",
       "      <td>0.578971</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CHROM       POS REF ALT  AF_ESP  AF_EXAC  AF_TGP  \\\n",
       "42457    13  52520508   G   A  0.0019  0.00126  0.0002   \n",
       "56604    19    855799   G   A  0.0000  0.00000  0.0000   \n",
       "34786    11  94194169   T   G  0.0000  0.00000  0.0000   \n",
       "27583     9  21971057   C   G  0.0000  0.00002  0.0000   \n",
       "16982     5    256472   G   A  0.2783  0.17160  0.3353   \n",
       "\n",
       "                                                CLNDISDB  \\\n",
       "42457  MedGen:C0019202,OMIM:277900,Orphanet:ORPHA905,...   \n",
       "56604  MedGen:C0221023,OMIM:162800,Orphanet:ORPHA2686...   \n",
       "34786                MedGen:C0027672,SNOMED_CT:699346009   \n",
       "27583  MedGen:C0027672,SNOMED_CT:699346009|MedGen:C15...   \n",
       "16982  Human_Phenotype_Ontology:HP:0002666,MedGen:C00...   \n",
       "\n",
       "                                                   CLNDN  \\\n",
       "42457          Wilson_disease|not_specified|not_provided   \n",
       "56604  Cyclical_neutropenia|Severe_congenital_neutrop...   \n",
       "34786            Hereditary_cancer-predisposing_syndrome   \n",
       "27583  Hereditary_cancer-predisposing_syndrome|Heredi...   \n",
       "16982  Pheochromocytoma|Leigh_syndrome|Hereditary_can...   \n",
       "\n",
       "                          CLNHGVS  ...   Codons STRAND BAM_EDIT         SIFT  \\\n",
       "42457  NC_000013.10:g.52520508G>A  ...  aCg/aTg   -1.0        0  deleterious   \n",
       "56604     NC_000019.9:g.855799G>A  ...        0    1.0       OK            0   \n",
       "34786   NC_000011.9:g.94194169T>G  ...  aAg/aCg   -1.0        0    tolerated   \n",
       "27583  NC_000009.11:g.21971057C>G  ...  Ggg/Cgg   -1.0       OK  deleterious   \n",
       "16982     NC_000005.9:g.256472G>A  ...  gtG/gtA    1.0       OK            0   \n",
       "\n",
       "                PolyPhen LoFtool CADD_PHRED  CADD_RAW BLOSUM62 CLASS  \n",
       "42457  probably_damaging  0.0340     33.000  6.889543     -1.0     1  \n",
       "56604                  0  0.0124      7.931  0.567842      NaN     0  \n",
       "34786             benign  0.2100     18.050  2.282571     -1.0     0  \n",
       "27583  probably_damaging  0.1440     25.900  5.364526     -2.0     0  \n",
       "16982                  0  0.4320      8.009  0.578971      NaN     0  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# my balancing\n",
    "# ===========================================================\n",
    "df_zero = df.loc[df['CLASS'] == 0]\n",
    "df_zero = df_zero.sample(n=10000)\n",
    "df_one = df.loc[df['CLASS'] == 1]\n",
    "df_one = df_one.sample(n=10000)\n",
    "\n",
    "df = pd.concat([df_zero, df_one])\n",
    "df = df.sample(n = df.shape[0])\n",
    "all_rows = df.values.tolist()\n",
    "row_num = len(all_rows)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Other people balancing \n",
    "# ===========================================================\n",
    "g = df.groupby('CLASS')\n",
    "df_balanced = g.apply(lambda x: x.sample(g.size().min()).reset_index(drop=True))\n",
    "# Extract smaller sample to avoid memory error later, when training starts\n",
    "df_balanced = df_balanced.sample(1000)\n",
    "\n",
    "# spliting data to training and testing\n",
    "# ===========================================================\n",
    "X = df_balanced.drop('CLASS',axis=1)\n",
    "# One hot encoding\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "y = df_balanced['CLASS']\n",
    "y = pd.get_dummies(y, drop_first=True)\n",
    "\n",
    "# Train/test split\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 6532 elements, new values have 37 elements",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-7872b5af3f58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mall_rows\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_X\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_rows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumns_backup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   5078\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5079\u001b[0m             \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5080\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5081\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5082\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/properties.pyx\u001b[0m in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_set_axis\u001b[0;34m(self, axis, labels)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mset_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m    153\u001b[0m             raise ValueError(\n\u001b[1;32m    154\u001b[0m                 \u001b[0;34m'Length mismatch: Expected axis has {old} elements, new '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m                 'values have {new} elements'.format(old=old_len, new=new_len))\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Length mismatch: Expected axis has 6532 elements, new values have 37 elements"
     ]
    }
   ],
   "source": [
    "all_rows = np.zeros((train_X.shape[0], train_X.shape[1] + 1))\n",
    "all_rows[:, :train_X.shape[1]] = train_X.values\n",
    "all_rows[:, train_X.shape[1]] = [l[0] for l in train_y.values.tolist()]\n",
    "df = pd.DataFrame(all_rows)\n",
    "df.columns = columns_backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_X.iloc[:, 6004]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification with Supervised Learning: Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision stump part for Adaboost\n",
    "# ===========================================================\n",
    "def is_numeric(value):\n",
    "    return isinstance(value, int) or isinstance(value, float)\n",
    "\n",
    "# === LeafNode is the prediction result of this branch ===\n",
    "class LeafNode:\n",
    "    def __init__(self, rows):\n",
    "        labels = [row[-1] for row in rows]\n",
    "        self.prediction = collections.Counter(labels)\n",
    "\n",
    "# === DecisionNode is an attribute / question used to partition the data ===\n",
    "class DecisionNode:\n",
    "    def __init__(self, question = None, left_branch = None, right_branch = None):\n",
    "        self.question = question\n",
    "        self.left_branch = left_branch\n",
    "        self.right_branch = right_branch\n",
    "    \n",
    "class DecisionTree:\n",
    "    def __init__(self, training_attribute, training_data, method = \"CART\"):\n",
    "        self.attribute = training_attribute     # takein attribute and data separately\n",
    "        self.train = training_data[1:]\n",
    "        self.row_num = len(self.train)\n",
    "        self.column_num = len(self.attribute)\n",
    "        self.method = method.upper()            # convert to upper case for general use\n",
    "        self.labels = self.uniq_val(-1)\n",
    "        if self.method not in [\"C4.5\", \"CART\", \"HYBRID\"]:\n",
    "            print(\"Error: Please choose a valid method!\")\n",
    "            return None\n",
    "        self.root = self.build_tree(self.train)\n",
    "    \n",
    "    def uniq_val(self, column):\n",
    "        return set([self.train[i][column] for i in range(len(self.train))])\n",
    "    \n",
    "    # when raising a question.\n",
    "    # if it's a categorical attribute, we simply iterate all categories\n",
    "    # if it's a numeric attribute, we iterate the set of possible numeric values \n",
    "    class Question:\n",
    "        def __init__(self, column, ref_value, attribute):\n",
    "            self.column = column\n",
    "            self.ref_value = ref_value if ref_value else \"None\"\n",
    "            self.attri = attribute\n",
    "\n",
    "        def match(self, row):\n",
    "            if is_numeric(self.ref_value):\n",
    "                try:\n",
    "                    return row[self.column] >= self.ref_value\n",
    "                except:\n",
    "                    print(\"Error occured in \", row)\n",
    "                    return True\n",
    "            else:\n",
    "                return row[self.column] == self.ref_value\n",
    "\n",
    "        def __repr__(self):\n",
    "            operand = \">=\" if is_numeric(self.ref_value) else \"==\"\n",
    "            return \"Is %s %s %s?\" % (self.attri[self.column], operand, str(self.ref_value))\n",
    "    \n",
    "    # === Method 1 - C4.5 ===\n",
    "    def entropy(self, rows):\n",
    "        # === Bits used to store the information ===\n",
    "        labels = [row[-1] for row in rows]\n",
    "        frequency = collections.Counter(labels).values()\n",
    "        pop = sum(frequency)\n",
    "        H = 0\n",
    "        for f in frequency:\n",
    "            p = f / pop\n",
    "            H -= p * math.log(p, 2)\n",
    "        return H\n",
    "    \n",
    "    # === Method 2 - CART ===\n",
    "    def gini(self, rows):\n",
    "        # === Probability of misclassifying any of your label, which is impurity ===\n",
    "        labels = [row[-1] for row in rows]\n",
    "        frequency = collections.Counter(labels).values()\n",
    "        pop = sum(frequency)\n",
    "        gini = 1\n",
    "        for f in frequency:\n",
    "            p = f / pop\n",
    "            gini -= p ** 2\n",
    "        return gini\n",
    "    \n",
    "    # === Calculate Gain Info ===\n",
    "    # I'm actually returning the gain info reduction\n",
    "    def info(self, branches, root):\n",
    "        # === Objective: to find the best question which can maximize info ===\n",
    "        root_size = float(len(root))\n",
    "        if self.method == \"C4.5\":  # Here I pick the GainRatio Approach\n",
    "            root_uncertainty = self.entropy(root)\n",
    "            gain_info = root_uncertainty\n",
    "            split_info = 0\n",
    "            for branch in branches:\n",
    "                if not branch: continue\n",
    "                gain_info -= len(branch) / root_size * self.entropy(branch)\n",
    "                split_info -= float(len(branch)) / root_size * math.log(float(len(branch)) / root_size)\n",
    "#                 print(gain_info, split_info)\n",
    "            return gain_info / split_info\n",
    "        elif self.method == \"CART\":\n",
    "            root_uncertainty = self.gini(root)\n",
    "            gain_info = root_uncertainty\n",
    "            for branch in branches:\n",
    "                if not branch: continue\n",
    "                gain_info -= len(branch) / root_size * self.gini(branch)\n",
    "            return gain_info\n",
    "        elif self.method == \"HYBRID\":\n",
    "            pass\n",
    "        pass\n",
    "    \n",
    "    # === Here I only do Binary Partitions ===\n",
    "    def partition(self, rows, question):\n",
    "        true_rows = []\n",
    "        false_rows = []\n",
    "        for row in rows:\n",
    "            if question.match(row):\n",
    "                true_rows.append(row)\n",
    "            else:\n",
    "                false_rows.append(row)\n",
    "        return true_rows, false_rows\n",
    "    \n",
    "    def find_best_question(self, rows):\n",
    "        max_info_attenuation = 0\n",
    "        best_question = self.Question(0, self.train[0][0], self.attribute)\n",
    "        # === Iterate through all question candidates ===\n",
    "        # === TODO: Maybe Iteration here can be optimized ===\n",
    "        for col in range(self.column_num - 1): # minus 1 to avoid using the label as attribute\n",
    "            ref_candidates = self.uniq_val(col)\n",
    "            for ref_value in ref_candidates:\n",
    "                if ref_value == \"null\": continue # avoid using null values to generate a question\n",
    "                q = self.Question(col, ref_value, self.attribute)\n",
    "                temp_true_rows, temp_false_rows = self.partition(rows, q)\n",
    "                temp_info_attenuation = self.info([temp_true_rows, temp_false_rows], rows)\n",
    "                if temp_info_attenuation >= max_info_attenuation:\n",
    "                    max_info_attenuation = temp_info_attenuation\n",
    "                    best_question = q\n",
    "        return max_info_attenuation, best_question\n",
    "        \n",
    "    # === Input rows of data with attributes and labels ===\n",
    "    def build_tree(self, rows):\n",
    "        # === Assign all rows as root of the whole decision tree ===\n",
    "        # === We have met the leaf node if gini(rows) is 0 or no question candidates left ===\n",
    "        gain_reduction, q = self.find_best_question(rows)\n",
    "#         if gain_reduction <= 0.003:\n",
    "        if self.gini(rows) <= 0.48:\n",
    "            return LeafNode(rows)\n",
    "        true_rows, false_rows = self.partition(rows, q)\n",
    "        # === Recursion after we have found a optimal question ===\n",
    "        return DecisionNode(q, self.build_tree(true_rows), self.build_tree(false_rows))\n",
    "    \n",
    "    # === Input a row of data with attributes (and no label), predict its label with our decision tree ===\n",
    "    # === Actually it can contain a label, we just don't use it ===\n",
    "    # === walk down the decision tree until we reach the leaf node ===\n",
    "    def classify(self, row, node):\n",
    "        if isinstance(node, LeafNode):\n",
    "#             print(\"===\", node.prediction)\n",
    "            return node.prediction\n",
    "        \n",
    "        if node.question.match(row):\n",
    "#             print(node.question, True)\n",
    "            return self.classify(row, node.left_branch)\n",
    "        else:\n",
    "#             print(node.question, False)\n",
    "            return self.classify(row, node.right_branch)\n",
    "    \n",
    "    def print_tree(self, node, spacing=\"\"):\n",
    "        # Base case: we've reached a leaf\n",
    "        if isinstance(node, LeafNode):\n",
    "            print (spacing + \"Predict\", node.prediction)\n",
    "            return\n",
    "\n",
    "        # Print the question at this node\n",
    "        print (spacing + str(node.question))\n",
    "\n",
    "        # Call this function recursively on the true branch\n",
    "        print (spacing + '--> True:')\n",
    "        self.print_tree(node.left_branch, spacing + \"  \")\n",
    "\n",
    "        # Call this function recursively on the false branch\n",
    "        print (spacing + '--> False:')\n",
    "        self.print_tree(node.right_branch, spacing + \"  \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide whole dataset into training set and testing set\n",
    "# ===========================================================\n",
    "training_percentage = 0.01  # percent of partition of training dataset\n",
    "training_size = int(row_num * training_percentage)\n",
    "testing_size = row_num - training_size\n",
    "training_attribute = list(df.columns)      # i omitted the 'CLASS' inside the decision tree structure\n",
    "training_data = all_rows[: training_size]  # training data should include header row\n",
    "testing_data = all_rows[training_size: ]   # testing data don't need to include header row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Trained! Time: 2.370s\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "# ===========================================================\n",
    "start = time.time()\n",
    "tree = DecisionTree(training_attribute, training_data, \"CART\")\n",
    "end = time.time()\n",
    "print(\"Decision Tree Trained! Time: %.03fs\" % (end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "print(tree.gini(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tree.print_tree(tree.root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: [====================] 100%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/frostace/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:30: RuntimeWarning: invalid value encountered in long_scalars\n"
     ]
    }
   ],
   "source": [
    "# Testing and Computing TN, TP, FN, FP, etc. \n",
    "# ===========================================================\n",
    "ROC = Table(make_array('CUTOFF', 'TN', 'FN', 'FP', 'TP', 'ACC'))\n",
    "step_size = 0.05\n",
    "CMap = {0: 'TN', 1: 'FN', 2: 'FP', 3: 'TP'}\n",
    "# 00(0) -> TN\n",
    "# 01(1) -> FN\n",
    "# 10(2) -> FP\n",
    "# 11(3) -> TP\n",
    "for cutoff in np.arange(0, 1 + step_size, step_size):\n",
    "    sys.stdout.write('\\r')\n",
    "    # the exact output you're looking for:\n",
    "    sys.stdout.write(\"Testing: [%-20s] %d%%\" % ('='*int(cutoff * 100 / 5), int(cutoff * 100)))\n",
    "    sys.stdout.flush()\n",
    "    Confusion = {'TN': 0, 'FN': 0, 'FP': 0, 'TP': 0}\n",
    "    for row in testing_data:\n",
    "        # prediction is a counter of label 1 and 0\n",
    "        pred_counter = tree.classify(row, tree.root)\n",
    "        true_rate = pred_counter.get(1, 0) / (pred_counter.get(1, 0) + pred_counter.get(0, 0) + 0.00000001)\n",
    "#         print(true_rate)\n",
    "        true_pred = 1 if true_rate >= cutoff else 0\n",
    "        indicator = (true_pred << 1) + row[-1]\n",
    "        # accordingly update confusion matrix\n",
    "        Confusion[CMap[indicator]] += 1\n",
    "    # concatenate the confusion matrix values into the overall ROC Table\n",
    "    thisline = [cutoff] + list(Confusion.values()) + [(Confusion['TP'] + Confusion['TN']) / sum(Confusion.values())]\n",
    "    ROC = ROC.with_row(thisline)\n",
    "ROC = ROC.with_column('SENSITIVITY', ROC.apply(lambda TP, FN: TP / (TP + FN + 0.00000001), 'TP', 'FN'))\n",
    "ROC = ROC.with_column('FPR', ROC.apply(lambda TN, FP: FP / (TN + FP + 0.00000001), 'TN', 'FP'))\n",
    "ROC = ROC.with_column('FMEAS', ROC.apply(lambda TP, FP, FN: 2 * (TP / (TP + FN)) * (TP / (TP + FP)) / (TP / (TP + FN) + TP / (TP + FP)), 'TP', 'FP', 'FN'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>CUTOFF</th> <th>TN</th> <th>FN</th> <th>FP</th> <th>TP</th> <th>ACC</th> <th>SENSITIVITY</th> <th>FPR</th> <th>FMEAS</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>0     </td> <td>0   </td> <td>0   </td> <td>9905</td> <td>9895</td> <td>0.499747</td> <td>1          </td> <td>1        </td> <td>0.666442 </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>0.05  </td> <td>1656</td> <td>326 </td> <td>8249</td> <td>9569</td> <td>0.566919</td> <td>0.967054   </td> <td>0.832812 </td> <td>0.690578 </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>0.1   </td> <td>2649</td> <td>899 </td> <td>7256</td> <td>8996</td> <td>0.588131</td> <td>0.909146   </td> <td>0.732559 </td> <td>0.68811  </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>0.15  </td> <td>3055</td> <td>997 </td> <td>6850</td> <td>8898</td> <td>0.603687</td> <td>0.899242   </td> <td>0.69157  </td> <td>0.693991 </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>0.2   </td> <td>3055</td> <td>997 </td> <td>6850</td> <td>8898</td> <td>0.603687</td> <td>0.899242   </td> <td>0.69157  </td> <td>0.693991 </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>0.25  </td> <td>3055</td> <td>997 </td> <td>6850</td> <td>8898</td> <td>0.603687</td> <td>0.899242   </td> <td>0.69157  </td> <td>0.693991 </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>0.3   </td> <td>3055</td> <td>997 </td> <td>6850</td> <td>8898</td> <td>0.603687</td> <td>0.899242   </td> <td>0.69157  </td> <td>0.693991 </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>0.35  </td> <td>3055</td> <td>997 </td> <td>6850</td> <td>8898</td> <td>0.603687</td> <td>0.899242   </td> <td>0.69157  </td> <td>0.693991 </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>0.4   </td> <td>5444</td> <td>2988</td> <td>4461</td> <td>6907</td> <td>0.623788</td> <td>0.698029   </td> <td>0.450379 </td> <td>0.649673 </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>0.45  </td> <td>5444</td> <td>2988</td> <td>4461</td> <td>6907</td> <td>0.623788</td> <td>0.698029   </td> <td>0.450379 </td> <td>0.649673 </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>0.5   </td> <td>5444</td> <td>2988</td> <td>4461</td> <td>6907</td> <td>0.623788</td> <td>0.698029   </td> <td>0.450379 </td> <td>0.649673 </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>0.55  </td> <td>5444</td> <td>2988</td> <td>4461</td> <td>6907</td> <td>0.623788</td> <td>0.698029   </td> <td>0.450379 </td> <td>0.649673 </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>0.6   </td> <td>5444</td> <td>2988</td> <td>4461</td> <td>6907</td> <td>0.623788</td> <td>0.698029   </td> <td>0.450379 </td> <td>0.649673 </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>0.65  </td> <td>7432</td> <td>4834</td> <td>2473</td> <td>5061</td> <td>0.63096 </td> <td>0.51147    </td> <td>0.249672 </td> <td>0.580756 </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>0.7   </td> <td>7432</td> <td>4834</td> <td>2473</td> <td>5061</td> <td>0.63096 </td> <td>0.51147    </td> <td>0.249672 </td> <td>0.580756 </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>0.75  </td> <td>9538</td> <td>9473</td> <td>367 </td> <td>422 </td> <td>0.50303 </td> <td>0.0426478  </td> <td>0.037052 </td> <td>0.0789966</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>0.8   </td> <td>9538</td> <td>9473</td> <td>367 </td> <td>422 </td> <td>0.50303 </td> <td>0.0426478  </td> <td>0.037052 </td> <td>0.0789966</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>0.85  </td> <td>9538</td> <td>9473</td> <td>367 </td> <td>422 </td> <td>0.50303 </td> <td>0.0426478  </td> <td>0.037052 </td> <td>0.0789966</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>0.9   </td> <td>9769</td> <td>9772</td> <td>136 </td> <td>123 </td> <td>0.499596</td> <td>0.0124305  </td> <td>0.0137304</td> <td>0.0242269</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>0.95  </td> <td>9769</td> <td>9772</td> <td>136 </td> <td>123 </td> <td>0.499596</td> <td>0.0124305  </td> <td>0.0137304</td> <td>0.0242269</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>1     </td> <td>9905</td> <td>9895</td> <td>0   </td> <td>0   </td> <td>0.500253</td> <td>0          </td> <td>0        </td> <td>nan      </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show\n",
    "ROC.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acc Curve by cutoff\n",
    "# ===========================================================\n",
    "# matplotlib.use('TkAgg')\n",
    "fig = plt.figure()\n",
    "plt.xlabel('Cutoff')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy - Cutoff of Decision Tree')\n",
    "plt.plot(np.arange(0, 1.1, 0.1), [0.5 for i in np.arange(0, 1.1, 0.1)], color='black')\n",
    "plt.plot(ROC.column('CUTOFF'), ROC.column('ACC'), color='orange')\n",
    "\n",
    "plt.axis([0, 1, 0, 1.1])\n",
    "plt.show()\n",
    "fig.savefig('Decision Tree ACC.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC_CURVE\n",
    "# ===========================================================\n",
    "fig = plt.figure()\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('Sensitivity')\n",
    "plt.title('ROC - Curve of Decision Tree')\n",
    "plt.plot(np.arange(0, 1.1, 0.1), np.arange(0, 1.1, 0.1), color='black')\n",
    "plt.plot(ROC.column('FPR'), ROC.column('SENSITIVITY'), color='orange')\n",
    "\n",
    "plt.legend(['Decision Tree', 'Null'])\n",
    "plt.axis([0, 1, 0, 1.1])\n",
    "plt.show()\n",
    "fig.savefig('Decision Tree ROC.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc = 0.669\n"
     ]
    }
   ],
   "source": [
    "# Compute AUC\n",
    "# ===========================================================\n",
    "length = len(ROC.column('FPR'))\n",
    "auc = 0\n",
    "for i in range(length - 1):\n",
    "    auc += 0.5 * abs(ROC.column('FPR')[i + 1] - ROC.column('FPR')[i]) * (ROC.column('SENSITIVITY')[i] + ROC.column('SENSITIVITY')[i + 1])\n",
    "print(\"auc = %.03f\" %auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7072377086012674\n"
     ]
    }
   ],
   "source": [
    "# Original Testing\n",
    "# ===========================================================\n",
    "\n",
    "accuracy = []\n",
    "for row in testing_data:\n",
    "    classification = tree.classify(row, tree.root)\n",
    "    if len(classification) == 1:\n",
    "        accuracy.append(int(classification.get(row[-1], 0) > 0))\n",
    "    else:\n",
    "        tot = sum(classification.values())\n",
    "        accuracy.append(classification.get(row[-1], 0) / tot)\n",
    "print(sum(accuracy) / len(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# My Decision Tree Model - before SMOTE\n",
    "# ===========================================================\n",
    "result = np.array([[0.1, 0.6052853830443929, 0.6341292591846538, 6.658, 0.2575948238372803], \n",
    "[0.2, 0.6696793630299119, 0.6462675119355091, 15.636898589134216, 0.26355624198913574], \n",
    "[0.3, 0.688320280645608, 0.6270048866889123, 15.349877572059631, 0.2788889408111572], \n",
    "[0.4, 0.6926441596845737, 0.6461577795177449, 17.142344093322755, 0.3045179843902588], \n",
    "[0.5, 0.7249279250111773, 0.6423258893248721, 20.893156909942626, 0.3267941474914551], \n",
    "[0.6, 0.6908789196403483, 0.6319173588785352, 23.121678400039674, 0.3292832374572754], \n",
    "[0.7, 0.6911146321003911, 0.6490688659793814, 26.19135489463806, 0.3296070098876953], \n",
    "[0.8, 0.681758435172271, 0.6396528437797009, 29.576567125320434, 0.3475379943847656], \n",
    "[0.9, 0.6796756798972815, 0.6486733420990525, 36.53753626346588, 0.37729477882385254], \n",
    "[1, 0.678894111630874, 0.6433185614453725, 40.28847301006317, 0.3777620792388916]])\n",
    "\n",
    "[percentage, my_acc, sklearn_acc, my_time_cost, sklearn_time_cost] = result.transpose()\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "color = 'tab:red'\n",
    "ax1.set_xlabel('Training Data Percentage(%)')\n",
    "ax1.set_ylabel('Time Consumption(s)', color=color)\n",
    "ax1.plot(percentage, my_time_cost, color=color)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "color = 'tab:green'\n",
    "ax2.set_ylabel('My Model - Accuracy', color=color)  # we already handled the x-label with ax1\n",
    "ax2.plot(percentage, my_acc, color=color)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "plt.ylim(0, 1)\n",
    "plt.title('My Decision Tree Performance')\n",
    "# plt.legend(['Time Consumption', 'My ACC'])\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "fig.savefig('Decision Tree Time & Acc by Training percentage.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sklearn Decision Tree Model - before SMOTE\n",
    "# ===========================================================\n",
    "fig, ax3 = plt.subplots()\n",
    "\n",
    "color = 'tab:red'\n",
    "ax3.set_xlabel('Training Data Percentage(%)')\n",
    "ax3.set_ylabel('Time Consumption(s)', color=color)\n",
    "ax3.plot(percentage, sklearn_time_cost, color=color)\n",
    "ax3.tick_params(axis='y', labelcolor=color)\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "ax4 = ax3.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "color = 'tab:green'\n",
    "ax4.set_ylabel('Sklearn - Accuracy', color=color)  # we already handled the x-label with ax1\n",
    "ax4.plot(percentage, sklearn_acc, color=color)\n",
    "ax4.tick_params(axis='y', labelcolor=color)\n",
    "plt.ylim(0, 1)\n",
    "plt.title('Sklearn Decision Tree Performance')\n",
    "# plt.legend(['Time Consumption', 'Sklearn ACC'])\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "fig.savefig('Decision Tree Time & Sklearn Acc by Training percentage.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 Models Comparison - Time Consumption\n",
    "# ===========================================================\n",
    "fig = plt.figure()\n",
    "plt.xlabel('Training Data Percentage(%)')\n",
    "plt.ylabel('Time Consumption(s)')\n",
    "plt.title('Decision Tree Time Consumption')\n",
    "plt.plot(percentage, my_time_cost, color='orange')\n",
    "plt.plot(percentage, sklearn_time_cost, color='black')\n",
    "plt.legend(['My Model', 'Sklearn Model'])\n",
    "plt.axis([0, 1, -5, 45])\n",
    "plt.show()\n",
    "fig.savefig('Decision Tree Time Consumption Comparison.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 Models Comparison - Accuracy\n",
    "# ===========================================================\n",
    "fig = plt.figure()\n",
    "plt.xlabel('Training Data Percentage(%)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Decision Tree Accuracy')\n",
    "plt.plot(percentage, my_acc, color='orange')\n",
    "plt.plot(percentage, sklearn_acc, color='black')\n",
    "plt.legend(['My Model: Avg = 68.0%', 'Sklearn Model: Avg = 64.1%'])\n",
    "plt.axis([0, 1, 0, 1])\n",
    "plt.show()\n",
    "fig.savefig('Decision Tree Accuracy Comparison.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label_distribution {0: 48754, 1: 16434}\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === toy data set ===\n",
    "training_data = [\n",
    "    ['Color', 'Diameter', 'Label'],\n",
    "    ['Green', 3, 'Apple'],\n",
    "    ['Yellow', 3, 'Apple'],\n",
    "    ['Red', 1, 'Grape'],\n",
    "    ['Red', 1, 'Grape'],\n",
    "    ['Yellow', 3, 'Lemon'],\n",
    "]\n",
    "testing_data = [\n",
    "    ['Red', 2, 'Grape'],\n",
    "    ['Yellow', 3.5, 'Apple'],\n",
    "    ['Green', 3, 'Apple']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-9caa82d76b5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Train Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Test acc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    814\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 816\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    817\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    378\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# spliting data to training and testing\n",
    "# ===========================================================\n",
    "df = df.fillna(0,inplace=True)\n",
    "X = df.drop('CLASS',axis=1)\n",
    "# One hot encoding\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "y = df['CLASS']\n",
    "y = pd.get_dummies(y, drop_first=True)\n",
    "\n",
    "# Train/test split\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y)\n",
    "\n",
    "# Normalize using StandardScaler\n",
    "scaler=StandardScaler()\n",
    "train_X=scaler.fit_transform(train_X)\n",
    "test_X=scaler.transform(test_X)\n",
    "\n",
    "# Train Model\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(train_X, train_y)\n",
    "\n",
    "# Test acc\n",
    "pred_y = model.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = accuracy_score(test_y, pred_y)\n",
    "confusion = confusion_matrix(test_y, pred_y)\n",
    "report = classification_report(test_y, pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.96705407, 0.90914603, 0.89924204, 0.89924204,\n",
       "       0.89924204, 0.89924204, 0.89924204, 0.69802931, 0.69802931,\n",
       "       0.69802931, 0.69802931, 0.69802931, 0.51147044, 0.51147044,\n",
       "       0.0426478 , 0.0426478 , 0.0426478 , 0.01243052, 0.01243052,\n",
       "       0.        ])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ROC.column('SENSITIVITY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
