{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import lib\n",
    "# ===========================================================\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import collections\n",
    "import math\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "from time import sleep\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "from datascience import *\n",
    "from scipy import stats\n",
    "\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize useful data\n",
    "# ===========================================================\n",
    "with open('clinvar_conflicting_clean.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    temp_rows = list(reader)\n",
    "df = pd.read_csv('clinvar_conflicting_clean.csv', low_memory=False)\n",
    "columns_to_change = ['ORIGIN', 'EXON', 'INTRON', 'STRAND', 'LoFtool', 'CADD_PHRED', 'CADD_RAW', 'BLOSUM62']\n",
    "df[['CLNVI', 'MC', 'SYMBOL', 'Feature_type', 'Feature', 'BIOTYPE', \n",
    " 'cDNA_position', 'CDS_position', 'Protein_position', 'Amino_acids', 'Codons', \n",
    " 'BAM_EDIT', 'SIFT', 'PolyPhen']] = df[['CLNVI', 'MC', 'SYMBOL', 'Feature_type', 'Feature', 'BIOTYPE', \n",
    " 'cDNA_position', 'CDS_position', 'Protein_position', 'Amino_acids', 'Codons', \n",
    " 'BAM_EDIT', 'SIFT', 'PolyPhen']].fillna(value=\"null\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map categorical data to numerical data\n",
    "# ===========================================================\n",
    "def uniq_val(column):\n",
    "    input_domain = set([column[i][0] for i in range(len(column))])\n",
    "    return input_domain\n",
    "\n",
    "def is_numeric(value):\n",
    "    return isinstance(value, int) or isinstance(value, float)\n",
    "\n",
    "def map_categ2numer():\n",
    "    for attribute in df.columns.values:\n",
    "        \n",
    "        if is_numeric(df[[attribute]].values[0]): continue\n",
    "        values_of_this_attrib = list(uniq_val(df[[attribute]].values))\n",
    "        length = len(values_of_this_attrib)\n",
    "        for i in range(length):\n",
    "#             print(values_of_this_attrib[i])\n",
    "            df[[attribute]] = df[[attribute]].replace(values_of_this_attrib[i], i / length)\n",
    "\n",
    "map_categ2numer()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(n = df.shape[0])\n",
    "all_rows = df.values.tolist()\n",
    "row_num = len(all_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide whole dataset into training set and testing set\n",
    "# ===========================================================\n",
    "training_percentage = 0.01  # percent of partition of training dataset\n",
    "training_size = int(row_num * training_percentage)\n",
    "testing_size = row_num - training_size\n",
    "trainingframe = df.iloc[: training_size]\n",
    "testingframe = df.iloc[training_size: ]\n",
    "trainingset = Table.from_df(trainingframe)\n",
    "testingset = Table.from_df(testingframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# formula = 'CLASS ~ CHROM + POS + REF + ALT + AF_ESP + AF_EXAC + AF_TGP + CLNDISDB + CLNDN + CLNVC + CLNVI + MC + ORIGIN + Allele + Consequence + IMPACT + SYMBOL + Feature_type + Feature + BIOTYPE + EXON + INTRON + cDNA_position + CDS_position + Protein_position + Amino_acids + Codons + STRAND + BAM_EDIT + SIFT + PolyPhen + LoFtool + CADD_PHRED + CADD_RAW + BLOSUM62'\n",
    "formula = 'CLASS ~ CHROM + POS + REF + ALT + AF_ESP + AF_EXAC + AF_TGP + CLNDISDB + CLNDN'\n",
    "selected_attribute = ['CHROM',\n",
    " 'POS',\n",
    " 'REF',\n",
    " 'ALT',\n",
    " 'AF_ESP',\n",
    " 'AF_EXAC',\n",
    " 'AF_TGP',\n",
    " 'CLNDISDB',\n",
    " 'CLNDN']\n",
    "# i removed 'CLNHGVS'\n",
    "# formula = 'CLASS ~ CLNVC + CLNVI + MC + ORIGIN + Allele + Consequence + IMPACT + SYMBOL'\n",
    "# formula = 'CLASS ~ Feature_type + Feature + BIOTYPE + EXON + INTRON + cDNA_position'\n",
    "# formula = 'CLASS ~ CDS_position + Protein_position + Amino_acids + Codons + STRAND + BAM_EDIT'\n",
    "# formula = 'CLASS ~ SIFT + PolyPhen + LoFtool + CADD_PHRED + CADD_RAW + BLOSUM62'\n",
    "model = smf.glm(formula=formula, data=trainingframe, \n",
    "                family=sm.families.Binomial(\n",
    "                link=sm.genmod.families.links.probit))\n",
    "result = model.fit()\n",
    "# result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = testingset.select(selected_attribute).to_df()\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = result.predict(testingset.select(selected_attribute).to_df())\n",
    "final = testingset.select('CLASS').with_column('PRE_CLASS', 1 - pred.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# Normalize grades to values between 0 and 1 for more efficient computation\n",
    "normalized_range = sklearn.preprocessing.MinMaxScaler(feature_range=(-1,1))\n",
    "\n",
    "# Extract Features + Labels\n",
    "labels.shape =  (100,) #scikit expects this\n",
    "features = normalized_range.fit_transform(features)\n",
    "\n",
    "# Create Test/Train\n",
    "features_train,features_test,labels_train,labels_test = train_test_split(features,labels,test_size=0.4)\n",
    "\n",
    "# Scikit Logistic Regression\n",
    "scikit_log_reg = LogisticRegression()\n",
    "scikit_log_reg.fit(features_train,labels_train)\n",
    "\n",
    "#Score is Mean Accuracy\n",
    "scikit_score = clf.score(features_test,labels_test)\n",
    "print 'Scikit score: ', scikit_score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
