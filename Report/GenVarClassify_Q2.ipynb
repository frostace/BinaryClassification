{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2: Evaluate the importance of all these features, find the most important one and analyze why is it so important.\n",
    "## Methodology: \n",
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import lib\n",
    "# ===========================================================\n",
    "from sklearn import tree\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "# from imblearn.over_sampling import SMOTENC\n",
    "import pandas as pd\n",
    "import time\n",
    "import sys\n",
    "import csv\n",
    "from datascience import *\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "plt.style.use('fivethirtyeight')\n",
    "import collections\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "from time import sleep\n",
    "# from RandomForestFunctions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize useful data\n",
    "# ===========================================================\n",
    "df = pd.read_csv('clinvar_conflicting_clean.csv', low_memory=False)\n",
    "df[['CLNVI', 'MC', 'SYMBOL', 'Feature_type', 'Feature', 'BIOTYPE', \n",
    " 'cDNA_position', 'CDS_position', 'Protein_position', 'Amino_acids', 'Codons', \n",
    " 'BAM_EDIT', 'SIFT', 'PolyPhen']] = df[['CLNVI', 'MC', 'SYMBOL', 'Feature_type', 'Feature', 'BIOTYPE', \n",
    " 'cDNA_position', 'CDS_position', 'Protein_position', 'Amino_acids', 'Codons', \n",
    " 'BAM_EDIT', 'SIFT', 'PolyPhen']].fillna(value=0)\n",
    "df_zero = df.loc[df['CLASS'] == 0]\n",
    "df_zero = df_zero.sample(n=10000)\n",
    "df_one = df.loc[df['CLASS'] == 1]\n",
    "df_one = df_one.sample(n=10000)\n",
    "\n",
    "df = pd.concat([df_zero, df_one])\n",
    "df = df.sample(n = df.shape[0])\n",
    "all_rows = df.values.tolist()\n",
    "row_num = len(all_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Split Train Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide whole dataset into training set and testing set\n",
    "# ===========================================================\n",
    "training_percentage = 0.01  # percent of partition of training dataset\n",
    "training_size = int(row_num * training_percentage)\n",
    "testing_size = row_num - training_size\n",
    "training_attribute = list(df.columns)[: -1]# should exclude 'CLASS'\n",
    "training_data = all_rows[: training_size]  # training data should include header row\n",
    "testing_data = all_rows[training_size: ]   # testing data don't need to include header row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Variable Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of attributes to use\n",
    "# ===========================================================\n",
    "rand_attribute_subset_len = 10  # can't too small, or it'll be hard for the tree to converge\n",
    "final_acc_list = []\n",
    "# final_time_list = []\n",
    "final_attribute = []\n",
    "forest_size = 2\n",
    "test_times = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Random Forest Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision stump part for Random Forest\n",
    "# ===========================================================\n",
    "def is_numeric(value):\n",
    "    return isinstance(value, int) or isinstance(value, float)\n",
    "\n",
    "# === LeafNode is the prediction result of this branch ===\n",
    "class LeafNode:\n",
    "    def __init__(self, rows):\n",
    "        labels = [row[-1] for row in rows]\n",
    "        self.prediction = collections.Counter(labels)\n",
    "\n",
    "# === DecisionNode is an attribute / question used to partition the data ===\n",
    "class DecisionNode:\n",
    "    def __init__(self, question = None, left_branch = None, right_branch = None):\n",
    "        self.question = question\n",
    "        self.left_branch = left_branch\n",
    "        self.right_branch = right_branch\n",
    "    \n",
    "class DecisionTree:\n",
    "    def __init__(self, all_attribs, training_attribs, training_data, method = \"CART\"):\n",
    "        self.training_attribs = training_attribs     # takein attribute and data separately\n",
    "        self.all_attribs = all_attribs\n",
    "        self.train = training_data\n",
    "        self.row_num = len(self.train)\n",
    "        self.attribute_colNums = [all_attribs.index(att) for att in training_attribs]\n",
    "        self.method = method.upper()            # convert to upper case for general use\n",
    "        self.labels = self.uniq_val(-1)\n",
    "        if self.method not in [\"C4.5\", \"CART\", \"HYBRID\"]:\n",
    "            print(\"Error: Please choose a valid method!\")\n",
    "            return None\n",
    "        self.root = self.build_tree(self.train)\n",
    "    \n",
    "    def uniq_val(self, column):\n",
    "        return set([self.train[i][column] for i in range(len(self.train))])\n",
    "    \n",
    "    # === when raising a question ===\n",
    "    # if it's a categorical attribute, we simply iterate all categories\n",
    "    # if it's a numeric attribute, we iterate the set of possible numeric values \n",
    "    class Question:\n",
    "        def __init__(self, column, ref_value, attribute):\n",
    "            self.column = column\n",
    "            self.ref_value = ref_value if ref_value else \"None\"\n",
    "            self.attri = attribute\n",
    "\n",
    "        def match(self, row):\n",
    "            if is_numeric(self.ref_value):\n",
    "                try:\n",
    "                    return row[self.column] >= self.ref_value\n",
    "                except:\n",
    "                    print(\"Error occured in \", row)\n",
    "                    return True\n",
    "            else:\n",
    "                return row[self.column] == self.ref_value\n",
    "\n",
    "        def __repr__(self):\n",
    "            operand = \">=\" if is_numeric(self.ref_value) else \"==\"\n",
    "            return \"Is %s %s %s?\" % (self.attri[self.column], operand, str(self.ref_value))\n",
    "    \n",
    "    # === Method 1 - C4.5 ===\n",
    "    def entropy(self, rows):\n",
    "        # === Bits used to store the information ===\n",
    "        labels = [row[-1] for row in rows]\n",
    "        frequency = collections.Counter(labels).values()\n",
    "        pop = sum(frequency)\n",
    "        H = 0\n",
    "        for f in frequency:\n",
    "            p = f / pop\n",
    "            H -= p * math.log(p, 2)\n",
    "        return H\n",
    "    \n",
    "    # === Method 2 - CART ===\n",
    "    def gini(self, rows):\n",
    "        # === Probability of misclassifying any of your label, which is impurity ===\n",
    "        labels = [row[-1] for row in rows]\n",
    "        frequency = collections.Counter(labels).values()\n",
    "        pop = sum(frequency)\n",
    "        gini = 1\n",
    "        for f in frequency:\n",
    "            p = f / pop\n",
    "            gini -= p ** 2\n",
    "        return gini\n",
    "    \n",
    "    # === Calculate Gain Info ===\n",
    "    # I'm actually returning the gain info reduction\n",
    "    def info(self, branches, root):\n",
    "        # === Objective: to find the best question which can maximize info ===\n",
    "        root_size = float(len(root))\n",
    "        if self.method == \"C4.5\":  # Here I pick the GainRatio Approach\n",
    "            root_uncertainty = self.entropy(root)\n",
    "            gain_info = root_uncertainty\n",
    "            split_info = 0\n",
    "            for branch in branches:\n",
    "                if not branch: continue\n",
    "                gain_info -= len(branch) / root_size * self.entropy(branch)\n",
    "                split_info -= float(len(branch)) / root_size * math.log(float(len(branch)) / root_size)\n",
    "#                 print(gain_info, split_info)\n",
    "            return gain_info / split_info\n",
    "        elif self.method == \"CART\":\n",
    "            root_uncertainty = self.gini(root)\n",
    "            gain_info = root_uncertainty\n",
    "            for branch in branches:\n",
    "                if not branch: continue\n",
    "                gain_info -= len(branch) / root_size * self.gini(branch)\n",
    "            return gain_info\n",
    "        elif self.method == \"HYBRID\":\n",
    "            pass\n",
    "        pass\n",
    "    \n",
    "    # Divide rows according to the question to true_rows and false_rows\n",
    "    # === Here I only do Binary Partitions ===\n",
    "    def partition(self, rows, question):\n",
    "        true_rows = []\n",
    "        false_rows = []\n",
    "        for row in rows:\n",
    "            if question.match(row):\n",
    "                true_rows.append(row)\n",
    "            else:\n",
    "                false_rows.append(row)\n",
    "        return true_rows, false_rows\n",
    "    \n",
    "    def find_best_question(self, rows):\n",
    "        max_info_attenuation = 0\n",
    "        best_question = self.Question(self.attribute_colNums[0], self.train[0][self.attribute_colNums[0]], self.all_attribs)\n",
    "        # === Iterate through all question candidates ===\n",
    "        # === TODO: Maybe Iteration here can be optimized ===\n",
    "        for col in self.attribute_colNums: # minus 1 to avoid using the label as attribute\n",
    "            ref_candidates = self.uniq_val(col)\n",
    "            for ref_value in ref_candidates:\n",
    "                if ref_value == \"null\" or not isinstance(ref_value, str) and np.isnan(ref_value): continue # avoid using null values to generate a question\n",
    "                q = self.Question(col, ref_value, self.all_attribs)\n",
    "                temp_true_rows, temp_false_rows = self.partition(rows, q)\n",
    "                temp_info_attenuation = self.info([temp_true_rows, temp_false_rows], rows)\n",
    "                if temp_info_attenuation >= max_info_attenuation:\n",
    "                    max_info_attenuation = temp_info_attenuation\n",
    "                    best_question = q\n",
    "        return max_info_attenuation, best_question\n",
    "    \n",
    "    # === Input rows of data with attributes and labels ===\n",
    "    def build_tree(self, rows):\n",
    "        # === Assign all rows as root of the whole decision tree ===\n",
    "        # === We have met the leaf node if gini(rows) is 0 or no question candidates left ===\n",
    "        gain_reduction, q = self.find_best_question(rows)\n",
    "        # gain here is actually info reduction\n",
    "#         if gain_reduction <= 0.001:\n",
    "        if self.gini(rows) <= 0.48:\n",
    "            return LeafNode(rows)\n",
    "        true_rows, false_rows = self.partition(rows, q)\n",
    "        # === Recursion after we have found a optimal question ===\n",
    "        return DecisionNode(q, self.build_tree(true_rows), self.build_tree(false_rows))\n",
    "    \n",
    "    # === Input a row of data with attributes (and no label), predict its label with our decision tree ===\n",
    "    # === Actually it can contain a label, we just don't use it ===\n",
    "    # === walk down the decision tree until we reach the leaf node ===\n",
    "    def classify(self, row, node):\n",
    "        if isinstance(node, LeafNode):\n",
    "#             print(\"===\", node.prediction)\n",
    "            return node.prediction\n",
    "        \n",
    "        if node.question.match(row):\n",
    "#             print(node.question, True)\n",
    "            return self.classify(row, node.left_branch)\n",
    "        else:\n",
    "#             print(node.question, False)\n",
    "            return self.classify(row, node.right_branch)\n",
    "    \n",
    "    def print_tree(self, node, spacing=\"\"):\n",
    "        # Base case: we've reached a leaf\n",
    "        if isinstance(node, LeafNode):\n",
    "            print (spacing + \"Predict\", node.prediction)\n",
    "            return\n",
    "\n",
    "        # Print the question at this node\n",
    "        print (spacing + str(node.question))\n",
    "\n",
    "        # Call this function recursively on the true branch\n",
    "        print (spacing + '--> True:')\n",
    "        self.print_tree(node.left_branch, spacing + \"  \")\n",
    "\n",
    "        # Call this function recursively on the false branch\n",
    "        print (spacing + '--> False:')\n",
    "        self.print_tree(node.right_branch, spacing + \"  \")\n",
    "    \n",
    "'''    def test(self):\n",
    "        for i in range(self.column_num):\n",
    "            q = self.Question(i, self.train[1][i], self.attribute)\n",
    "            print(q)\n",
    "            print(q.match(1))'''\n",
    "    \n",
    "def bootstrapped_dataset(rows, size):\n",
    "    n = len(rows)\n",
    "    bootstrapped_rows = []\n",
    "    # here i should pick rand_idx with replacement, which is bootstrapping\n",
    "    rand_idx = np.random.choice(n, size, replace=True)\n",
    "    for i in rand_idx:\n",
    "        bootstrapped_rows.append(rows[i])\n",
    "    return bootstrapped_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Train Random Forest for each Fixed Attribute except 'CLASS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for: CHROM\n",
      "Random Forest Trained! Time: 0.155s\n",
      "Random Forest Trained! Time: 0.258s\n",
      "Random Forest Trained! Time: 0.411s\n",
      "Random Forest Trained! Time: 0.511s\n",
      "Random Forest Tested! Time: 1.298s\n",
      "0.5820075757575758 1.2975522875785828\n",
      "Training for: POS\n",
      "Random Forest Trained! Time: 0.039s\n",
      "Random Forest Trained! Time: 0.178s\n",
      "Random Forest Trained! Time: 0.354s\n",
      "Random Forest Trained! Time: 0.452s\n",
      "Random Forest Tested! Time: 1.156s\n",
      "0.5853787878787878 1.1560677886009216\n",
      "Training for: REF\n",
      "Random Forest Trained! Time: 0.051s\n",
      "Random Forest Trained! Time: 0.273s\n",
      "Random Forest Trained! Time: 0.384s\n",
      "Random Forest Trained! Time: 0.551s\n",
      "Random Forest Tested! Time: 1.409s\n",
      "0.5154166666666666 1.4090960025787354\n",
      "Training for: ALT\n",
      "Random Forest Trained! Time: 0.141s\n",
      "Random Forest Trained! Time: 0.275s\n",
      "Random Forest Trained! Time: 0.336s\n",
      "Random Forest Trained! Time: 0.396s\n",
      "Random Forest Tested! Time: 1.012s\n",
      "0.587260101010101 1.0123035311698914\n",
      "Training for: AF_ESP\n",
      "Random Forest Trained! Time: 0.101s\n",
      "Random Forest Trained! Time: 0.173s\n",
      "Random Forest Trained! Time: 0.279s\n",
      "Random Forest Trained! Time: 0.375s\n",
      "Random Forest Tested! Time: 0.965s\n",
      "0.630959595959596 0.9650072455406189\n",
      "Training for: AF_EXAC\n",
      "Random Forest Trained! Time: 0.055s\n",
      "Random Forest Trained! Time: 0.124s\n",
      "Random Forest Trained! Time: 0.174s\n",
      "Random Forest Trained! Time: 0.269s\n",
      "Random Forest Tested! Time: 0.693s\n",
      "0.6412878787878789 0.6928507089614868\n",
      "Training for: AF_TGP\n",
      "Random Forest Trained! Time: 0.179s\n",
      "Random Forest Trained! Time: 0.265s\n",
      "Random Forest Trained! Time: 0.400s\n",
      "Random Forest Trained! Time: 0.512s\n",
      "Random Forest Tested! Time: 1.303s\n",
      "0.6142171717171717 1.3026772737503052\n",
      "Training for: CLNDISDB\n",
      "Random Forest Trained! Time: 0.053s\n",
      "Random Forest Trained! Time: 0.230s\n",
      "Random Forest Trained! Time: 0.380s\n",
      "Random Forest Trained! Time: 0.582s\n",
      "Random Forest Tested! Time: 1.502s\n",
      "0.6206060606060606 1.5017017126083374\n",
      "Training for: CLNDN\n",
      "Random Forest Trained! Time: 0.162s\n",
      "Random Forest Trained! Time: 0.245s\n",
      "Random Forest Trained! Time: 0.440s\n",
      "Random Forest Trained! Time: 0.525s\n",
      "Random Forest Tested! Time: 1.334s\n",
      "0.5701767676767676 1.333637535572052\n",
      "Training for: CLNHGVS\n",
      "Random Forest Trained! Time: 0.123s\n",
      "Random Forest Trained! Time: 0.239s\n",
      "Random Forest Trained! Time: 0.447s\n",
      "Random Forest Trained! Time: 0.558s\n",
      "Random Forest Tested! Time: 1.422s\n",
      "0.5971969696969697 1.4217966794967651\n",
      "Training for: CLNVC\n",
      "Random Forest Trained! Time: 0.115s\n",
      "Random Forest Trained! Time: 0.195s\n",
      "Random Forest Trained! Time: 0.234s\n",
      "Random Forest Trained! Time: 0.346s\n",
      "Random Forest Tested! Time: 0.896s\n",
      "0.5890151515151515 0.8956245183944702\n",
      "Training for: CLNVI\n",
      "Random Forest Trained! Time: 0.148s\n",
      "Random Forest Trained! Time: 0.272s\n",
      "Random Forest Trained! Time: 0.406s\n",
      "Random Forest Trained! Time: 0.509s\n",
      "Random Forest Tested! Time: 1.304s\n",
      "0.55114898989899 1.303686797618866\n",
      "Training for: MC\n",
      "Random Forest Trained! Time: 0.189s\n",
      "Random Forest Trained! Time: 0.261s\n",
      "Random Forest Trained! Time: 0.396s\n",
      "Random Forest Trained! Time: 0.565s\n",
      "Random Forest Tested! Time: 1.453s\n",
      "0.591010101010101 1.453306257724762\n",
      "Training for: ORIGIN\n",
      "Random Forest Trained! Time: 0.114s\n",
      "Random Forest Trained! Time: 0.209s\n",
      "Random Forest Trained! Time: 0.284s\n",
      "Random Forest Trained! Time: 0.359s\n",
      "Random Forest Tested! Time: 0.935s\n",
      "0.5835353535353536 0.9353012442588806\n",
      "Training for: Allele\n",
      "Random Forest Trained! Time: 0.084s\n",
      "Random Forest Trained! Time: 0.190s\n",
      "Random Forest Trained! Time: 0.314s\n",
      "Random Forest Trained! Time: 0.422s\n",
      "Random Forest Tested! Time: 1.085s\n",
      "0.5998106060606061 1.0854430198669434\n",
      "Training for: Consequence\n",
      "Random Forest Trained! Time: 0.098s\n",
      "Random Forest Trained! Time: 0.296s\n",
      "Random Forest Trained! Time: 0.402s\n",
      "Random Forest Trained! Time: 0.455s\n",
      "Random Forest Tested! Time: 1.156s\n",
      "0.548510101010101 1.1562705039978027\n",
      "Training for: IMPACT\n",
      "Random Forest Trained! Time: 0.070s\n",
      "Random Forest Trained! Time: 0.146s\n",
      "Random Forest Trained! Time: 0.247s\n",
      "Random Forest Trained! Time: 0.356s\n",
      "Random Forest Tested! Time: 0.925s\n",
      "0.579469696969697 0.9250637888908386\n",
      "Training for: SYMBOL\n",
      "Random Forest Trained! Time: 0.077s\n",
      "Random Forest Trained! Time: 0.238s\n",
      "Random Forest Trained! Time: 0.437s\n",
      "Random Forest Trained! Time: 0.846s\n",
      "Random Forest Tested! Time: 2.239s\n",
      "0.5745959595959595 2.2386982440948486\n",
      "Training for: Feature_type\n",
      "Random Forest Trained! Time: 0.134s\n",
      "Random Forest Trained! Time: 0.240s\n",
      "Random Forest Trained! Time: 0.372s\n",
      "Random Forest Trained! Time: 0.436s\n",
      "Random Forest Tested! Time: 1.110s\n",
      "0.5750126262626263 1.1100552678108215\n",
      "Training for: Feature\n",
      "Random Forest Trained! Time: 0.174s\n",
      "Random Forest Trained! Time: 0.283s\n",
      "Random Forest Trained! Time: 0.355s\n",
      "Random Forest Trained! Time: 0.538s\n",
      "Random Forest Tested! Time: 1.405s\n",
      "0.5780681818181819 1.405188262462616\n",
      "Training for: BIOTYPE\n",
      "Random Forest Trained! Time: 0.111s\n",
      "Random Forest Trained! Time: 0.286s\n",
      "Random Forest Trained! Time: 0.435s\n",
      "Random Forest Trained! Time: 0.519s\n",
      "Random Forest Tested! Time: 1.329s\n",
      "0.5746212121212122 1.3289732933044434\n",
      "Training for: EXON\n",
      "Random Forest Trained! Time: 0.134s\n",
      "Random Forest Trained! Time: 0.186s\n",
      "Random Forest Trained! Time: 0.298s\n",
      "Random Forest Trained! Time: 0.384s\n",
      "Random Forest Tested! Time: 0.985s\n",
      "0.5843055555555555 0.9853947758674622\n",
      "Training for: INTRON\n",
      "Random Forest Trained! Time: 0.106s\n",
      "Random Forest Trained! Time: 0.202s\n",
      "Random Forest Trained! Time: 0.303s\n",
      "Random Forest Trained! Time: 0.372s\n",
      "Random Forest Tested! Time: 0.946s\n",
      "0.6129292929292929 0.9459867477416992\n",
      "Training for: cDNA_position\n",
      "Random Forest Trained! Time: 0.107s\n",
      "Random Forest Trained! Time: 0.257s\n",
      "Random Forest Trained! Time: 0.354s\n",
      "Random Forest Trained! Time: 0.555s\n",
      "Random Forest Tested! Time: 1.437s\n",
      "0.5683838383838383 1.4369537234306335\n",
      "Training for: CDS_position\n",
      "Random Forest Trained! Time: 0.075s\n",
      "Random Forest Trained! Time: 0.150s\n",
      "Random Forest Trained! Time: 0.444s\n",
      "Random Forest Trained! Time: 0.628s\n",
      "Random Forest Tested! Time: 1.612s\n",
      "0.6068434343434344 1.6119904518127441\n",
      "Training for: Protein_position\n",
      "Random Forest Trained! Time: 0.173s\n",
      "Random Forest Trained! Time: 0.254s\n",
      "Random Forest Trained! Time: 0.315s\n",
      "Random Forest Trained! Time: 0.543s\n",
      "Random Forest Tested! Time: 1.410s\n",
      "0.5695454545454546 1.4096567630767822\n",
      "Training for: Amino_acids\n",
      "Random Forest Trained! Time: 0.127s\n",
      "Random Forest Trained! Time: 0.212s\n",
      "Random Forest Trained! Time: 0.342s\n",
      "Random Forest Trained! Time: 0.503s\n",
      "Random Forest Tested! Time: 1.304s\n",
      "0.5292929292929294 1.3036617636680603\n",
      "Training for: Codons\n",
      "Random Forest Trained! Time: 0.049s\n",
      "Random Forest Trained! Time: 0.181s\n",
      "Random Forest Trained! Time: 0.298s\n",
      "Random Forest Trained! Time: 0.471s\n",
      "Random Forest Tested! Time: 1.208s\n",
      "0.610189393939394 1.2075687050819397\n",
      "Training for: STRAND\n",
      "Random Forest Trained! Time: 0.073s\n",
      "Random Forest Trained! Time: 0.124s\n",
      "Random Forest Trained! Time: 0.307s\n",
      "Random Forest Trained! Time: 0.437s\n",
      "Random Forest Tested! Time: 1.128s\n",
      "0.5731313131313132 1.1276084780693054\n",
      "Training for: BAM_EDIT\n",
      "Random Forest Trained! Time: 0.057s\n",
      "Random Forest Trained! Time: 0.180s\n",
      "Random Forest Trained! Time: 0.314s\n",
      "Random Forest Trained! Time: 0.411s\n",
      "Random Forest Tested! Time: 1.058s\n",
      "0.571590909090909 1.057993233203888\n",
      "Training for: SIFT\n",
      "Random Forest Trained! Time: 0.045s\n",
      "Random Forest Trained! Time: 0.213s\n",
      "Random Forest Trained! Time: 0.425s\n",
      "Random Forest Trained! Time: 0.547s\n",
      "Random Forest Tested! Time: 1.416s\n",
      "0.5736742424242425 1.4161382913589478\n",
      "Training for: PolyPhen\n",
      "Random Forest Trained! Time: 0.091s\n",
      "Random Forest Trained! Time: 0.284s\n",
      "Random Forest Trained! Time: 0.454s\n",
      "Random Forest Trained! Time: 0.529s\n",
      "Random Forest Tested! Time: 1.343s\n",
      "0.5764267676767677 1.3428382277488708\n",
      "Training for: LoFtool\n",
      "Random Forest Trained! Time: 0.064s\n",
      "Random Forest Trained! Time: 0.176s\n",
      "Random Forest Trained! Time: 0.242s\n",
      "Random Forest Trained! Time: 0.323s\n",
      "Random Forest Tested! Time: 0.837s\n",
      "0.5654924242424242 0.8373909592628479\n",
      "Training for: CADD_PHRED\n",
      "Random Forest Trained! Time: 0.085s\n",
      "Random Forest Trained! Time: 0.169s\n",
      "Random Forest Trained! Time: 0.286s\n",
      "Random Forest Trained! Time: 0.376s\n",
      "Random Forest Tested! Time: 0.959s\n",
      "0.6321464646464646 0.9591623544692993\n",
      "Training for: CADD_RAW\n",
      "Random Forest Trained! Time: 0.069s\n",
      "Random Forest Trained! Time: 0.199s\n",
      "Random Forest Trained! Time: 0.382s\n",
      "Random Forest Trained! Time: 0.515s\n",
      "Random Forest Tested! Time: 1.327s\n",
      "0.5961994949494949 1.327351987361908\n",
      "Training for: BLOSUM62\n",
      "Random Forest Trained! Time: 0.092s\n",
      "Random Forest Trained! Time: 0.280s\n",
      "Random Forest Trained! Time: 0.589s\n",
      "Random Forest Trained! Time: 0.729s\n",
      "Random Forest Tested! Time: 1.865s\n",
      "0.5473611111111111 1.8652817010879517\n"
     ]
    }
   ],
   "source": [
    "for fixed_attribute in training_attribute:\n",
    "\tremaining_attribute = list(training_attribute)\n",
    "\tremaining_attribute.remove(fixed_attribute)\n",
    "\n",
    "\tprint(\"Training for: %s\" % fixed_attribute)\n",
    "\n",
    "\tstart = time.time()\n",
    "\n",
    "\tfinal_acc = 0\n",
    "\n",
    "\tfor pp in range(test_times):\n",
    "\n",
    "\t\t# Training Random Forest\n",
    "\t\t# ===========================================================\n",
    "\t\trandom_forest = []\n",
    "\t\t\n",
    "\t\tfor i in range(forest_size):\n",
    "\t\t\trand_attribute_subset = np.random.choice(a=remaining_attribute, size=rand_attribute_subset_len - 1)\n",
    "\t\t\trand_attribute_subset = np.append(rand_attribute_subset, fixed_attribute)\n",
    "\t\t\t# print(rand_attribute_subset)\n",
    "\t\t\ttraining_data = bootstrapped_dataset(all_rows, training_size)\n",
    "\t\t\ttree = DecisionTree(training_attribute, rand_attribute_subset, training_data, \"CART\")\n",
    "# \t\t\ttree.print_tree(tree.root)\n",
    "\t\t\trandom_forest.append(tree)\n",
    "\n",
    "\t\tend = time.time()\n",
    "\t\tprint(\"Random Forest Trained! Time: %.03fs\" % ((end - start) / 10))\n",
    "\n",
    "\t\t# Testing Random Forest, Computing TN, TP, FN, FP, etc.\n",
    "\t\t# ===========================================================\n",
    "\n",
    "\t\tCMap = {0: 'TN', 1: 'FN', 2: 'FP', 3: 'TP'}\n",
    "\t\tcutoff = 0.5\n",
    "\t\tConfusion = {'TN': 0, 'FN': 0, 'FP': 0, 'TP': 0}\n",
    "\t\tfor row in testing_data:\n",
    "\t\t\ttrue_rate_forest = 0\n",
    "\t\t\tfor tree_i in random_forest:\n",
    "\n",
    "\t\t\t\t# prediction is a counter of label 1 and 0\n",
    "\t\t\t\tpred_counter = tree_i.classify(row, tree_i.root)\n",
    "\t\t\t\ttrue_rate_tree = pred_counter.get(1, 0) / (pred_counter.get(1, 0) + pred_counter.get(0, 0) + 0.00000001)\n",
    "\t\t\t\ttrue_rate_forest += true_rate_tree\n",
    "\t\t\ttrue_rate_forest /= forest_size\n",
    "\t\t\ttrue_pred = 1 if true_rate_forest >= cutoff else 0\n",
    "\t\t\tindicator = (true_pred << 1) + row[-1]\n",
    "\n",
    "\t\t\t# accordingly update confusion matrix\n",
    "\t\t\tConfusion[CMap[indicator]] += 1\n",
    "\t\t\t\n",
    "\t\tfinal_acc += (Confusion['TP'] + Confusion['TN']) / sum(Confusion.values())\n",
    "\n",
    "\tend = time.time()\n",
    "\tprint(\"Random Forest Tested! Time: %.03fs\" % ((end - start) / test_times))\n",
    "\tfinal_acc /= test_times\n",
    "\tprint(final_acc, ((end - start) / test_times))\n",
    "\tfinal_acc_list.append(final_acc)\n",
    "\tfinal_attribute.append(fixed_attribute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>Attribute</th> <th>Acc</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>AF_EXAC     </td> <td>0.641288</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>CADD_PHRED  </td> <td>0.632146</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>AF_ESP      </td> <td>0.63096 </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>CLNDISDB    </td> <td>0.620606</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>AF_TGP      </td> <td>0.614217</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>INTRON      </td> <td>0.612929</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Codons      </td> <td>0.610189</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>CDS_position</td> <td>0.606843</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Allele      </td> <td>0.599811</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>CLNHGVS     </td> <td>0.597197</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>\n",
       "<p>... (26 rows omitted)</p>"
      ],
      "text/plain": [
       "Attribute    | Acc\n",
       "AF_EXAC      | 0.641288\n",
       "CADD_PHRED   | 0.632146\n",
       "AF_ESP       | 0.63096\n",
       "CLNDISDB     | 0.620606\n",
       "AF_TGP       | 0.614217\n",
       "INTRON       | 0.612929\n",
       "Codons       | 0.610189\n",
       "CDS_position | 0.606843\n",
       "Allele       | 0.599811\n",
       "CLNHGVS      | 0.597197\n",
       "... (26 rows omitted)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight = Table()\n",
    "weight = weight.with_columns('Attribute', final_attribute, 'Acc', final_acc_list)\n",
    "weight.sort(1, descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Below are script cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is SIFT == tolerated?\n",
      "--> True:\n",
      "  Is POS >= 32913320?\n",
      "  --> True:\n",
      "    Predict Counter({1: 15, 0: 5})\n",
      "  --> False:\n",
      "    Predict Counter({0: 6, 1: 1})\n",
      "--> False:\n",
      "  Is POS >= 47412703?\n",
      "  --> True:\n",
      "    Predict Counter({0: 65, 1: 38})\n",
      "  --> False:\n",
      "    Is POS >= 43503710?\n",
      "    --> True:\n",
      "      Predict Counter({1: 5})\n",
      "    --> False:\n",
      "      Is LoFtool >= 0.13699999999999998?\n",
      "      --> True:\n",
      "        Predict Counter({1: 15, 0: 10})\n",
      "      --> False:\n",
      "        Predict Counter({0: 26, 1: 14})\n"
     ]
    }
   ],
   "source": [
    "tree.print_tree(tree.root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
